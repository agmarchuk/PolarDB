## Начинаем
Раздел предназначен для пробы и практического осваивания элементов предлагаемой технологии.

Раздел начальных проб организован как набор простых программ в проекте GetStarted. Все программы реализованы под
.NET Core. Для их опробования, надо сформировать обстановку .NET Core. Это можно сделать либо через Visual Studio 2015 (или более позднюю) или через самостоятельную систему программирования. Детали установки и основы работы, можно посмотреть на сайте http://asp.net. Второй вариант обстановки можно рекомендовать если Вы легко работаете в командной строке и если Вам лень устанавливать "монстра" VS 2015. 

Для удобства, все демонстрационные программы оформлены как статические методы public static void MainX() и для запуска
соответствующей программы, нужно ее указать в "настоящем" Main(). 

#### Main1()
Программа демонстрирует некоторые простые возможности пакета PolarDB. 

Принципиальным является использование типизации для структурных значений. Сначала формируется некоторый тип, или некоторые
типы, а потом тип или типы используются для организации работы. В примере, создан тип записи, состоящей из трех полей.
Далее, показывается, что объектное представление структурной константы может быть проинтерпретировано как поляровское
структурное значение в контексте указанного типа. 

Основная форма существования структурных значений в Поляре - в виде потока байтов, обычно в файле. Чтобы не мусорить в 
файловой системе, создается поток (Stream) в ОЗУ, на базе этого стрима создается ячейка класса PaCell. Важно отметить, 
что ячейка создается под конкретный тип. Соответственно, константное структурное значение помещается в ячейку:
cell.Fill(структурная константа, которая соответствует заданному типу);

Главным способом работы с ячейками, это помещение (замена предыдущего) или взятие значения из какого-то поля. В данном 
случае, берется первое (нумерация начинается с 0) поле значения из поля Root. Естественно, что ячейка не сохраняется 
между запусками. 

#### Main2()
Программа демонстрирует создание таблицы и простого сортировочного индекса для эффективного доступа по идентификатору
записи. 

Теперь придется "мусорить" в файловой системе, файлы, порождаемые в тестах размещаются в ./Databases. Но сами программы
ничего не уничтожают, пользователю необходимо самому следить за файлами и вовремя "чистить". Не забудьте поменять вызов
программы в Main() (Файл Program)!

В данной демонстрации, создается таблица, имеющая тип последовательности записи, состоящей из трех полей (обратите внимание!), определяется еще один тип (последовательность записей из двух полей). Дальше производится формирование
основной таблицы и индекса. Обратите внимание как это делается: сначала создается пустая последовательность, потом 
к ней добавляются элементы в объектном структурном представлении. В конце делается Flush() - это обязательно, это
для того, чтобы закончить построение массива на диске.  

Потом идет испытание корректности работы поиска элемента по заданному целочисленному идентификатору (ключу). И под конец,
выполняется много поисков с разными значениями идентификаторов. Замеряется время. У меня получается 54 мс. на одну тысячу
поисков. 

Мы еще ничего не делали, а уже получили рекорд! Аналогичная задача выполняется
MS SQL Server 270 ms, MySQL 310 ms, SQLite 800 ms на 1000 тыс. поисков.
Не надо обольщаться, основная часть проигрыша определяется более громоздким запуском поиска в вышеперечисленных обстановках. Но что Вам нужно? Громоздкий запуск или быстрый поиск?     

Раздел формирования базы данных и создания индекса, выполняется в режиме toload == true. Один раз сформировав базе данных, вы запуски можете выполнять с в режиме toload == false. База данных очень быстро откликается на запросы. Это тоже - преимущество. 
        
#### Main3()
Программа демонстрирует решение предыдущей задачи (таблица + индекс) с использованием специального универсального индекса UniversalIndex. Для чего это нужно? Простой сортировочный индекс не достаточно гибок и недостаточно эффективен. В универсальном решении заложены и гибкость и эффективность. Гибкость проявляется в том, что теперь позволено добавлять новые записи и после создания индекса. Увеличение эффективности происходит из-за добавления так называемой шкалы (появляется третий файл), своего рода индекса к индексу. 

Результаты прогона дают 26 мс. на 1000 поисков, что более, чем в 2 раза улучшает решение с использованием простого индекса. Новую функциональность вида добавление и уничтожение элементов в динамике доступа к ним, тест не демонстрирует.  

#### Main4()
Программа демонстрирует решение предыдущей задачи (таблица + индекс), предыдущим решением (с использованием универсального индекса), но в среде страничного хранилища PagedFileStore и с использованием кеша этого хранилища.

Страничное хранилище используется несколько коряво, но, в принципе - понятно.  

Обратите внимание на то, что теперь все используемые файлы упакованы в одно хранилище - файл storage.bin
В реальных базах данных создается несколько десятков таблиц, к ним - множество индексов и вся эта "картина" еще и меняется в динамике работы.

Производительность решения опять выросла. Теперь она достигла 9 мс. на 1000 поисков. Правда замедлилось построение индексов. Надо же чем-то жертвовать... Кстати, "классические" MS SQL Server и MySQL также не могут "похвастаться" быстрой загрузкой. Правда там еще транзакции поддерживаются... 

#### Main5()
Программа демонстрирует некоторое модельное "предельное" решение предыдущей задачи. Строится, как всегда, основная таблица и строится сортировочный индекс, но индекс выполняется в две разнесенных по ячейкам последовательности. Для использования, из базы данных извлекается массив ключей. Соответственно поиск происходит сначала в массиве ключей, там ищется (методом дихотомии) индекс элемента с совпадающим с образцом ключом. Потом по этому индексу в третьей ячейке считывается единственный элемент - офсет в основной последовательности элемента, в котором ключ совпадает с образцом. И последняя операция - соответствующая запись по этому офсету прочитывается.    
После построение базы данных, выполняется тест на производительность выборки по идентификатору (ключу). Поскольку часы уже начинают измерять слишком малые промежутки, тест выполняется не 1 тыс. раз, а 100 тыс раз.  

Результат измерения - вновь улучшает скорость. Теперь 100 тыс выборок выполняется за 290 мс. Т.е. 2.9 мс. на 1000. 

#### Main6()
Программа продолжает выстраивание обработки последовательности записей {id, name, age}. Только теперь идентификатор определен как строковый. Показано, что решениями серии UniversalIndex можно сделать организовать обработку строкового поля id со скоростями, не слишком меньшими, чем целочисленного. Время выполнения 1000 запросов на выборку записи по идентификатору, составляет около 30 мс. Для данных размера 10 млн. записей, рекомендуется провести некоторые эксперименты. Базовый прогон - формирование базы данных и индексов, выполнение в цикле запросов на данные по случайно сгенерированным идентификаторам. Далее, можно изменить параметр toload на ложь и посмотреть скорость доступов. Наиболее интересным экспериментом является отключение загрузки кеша, строка ps_store.LoadCache(), перезагрузка компьютера и выполнение серии доступов. Результат на 10 млн. данных подучился: 88 сек. на 10 тыс. поисков. Это является разящим контрастом к результатом базового прогона, когда кеш или активен из-за загрузки и вычислений, или из-за специального действия по загрузке кеша. А это действие на 10 млн. записей происходит 3.6 секунды. Для меньшего количества поисков скорость поиска будет еще меньше. Можно сделать вывод, что "разогрев" в динамике работы не всегда будет эффективным, желательно для этих случаев разогрев проводить специально.        

