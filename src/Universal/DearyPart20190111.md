
### 20190111 21:02
Вот решил и дневник перенести в удобное место. Потом просто скомбинирую файлы и помещу туда, куда надо.

Сейчас надо "приделать" шкалу. Посмотрю как это делалось ранее. 

Какую-то шкалу "приделал", надо испытать. Сначала без шкалы на домашнем компьютере. Загрузк 9.4 сек., выборка 862 / 10 тыс.

Похоже, сработало. Загрузка 10.3 сек., выборка 121 / 10 тыс. Без загрузки, но с подготовкой Prepare() выборка 141, 127 / 10 тыс. Prepare на 10 млн. выполнялась 1.3 сек. 

### 20190112 11:58
Что-то получилось и это хорошо. Однако я понял, что пошел по ложному пути в конструировании индекса. Думаю, все должно быть проще и эффективнее. Надо делать индекс не из абстактных элементов, а ключа и офсета. Потом добавить шкалу. Соответственно, конструктор должен иметь возможность порождать последовательности. Кстати, генератор там уже есть. А вот keyProducer не нужен. В общем, надо перерабатывать.   

Начал энергично перерабатывать и "уперся" в то, что общую конструкцию я упустил и пришлось сходить погулять для того, чтобы подумать. Размышления привели к следующему. Совсем индивидуально работать с каждым индексом не получится - есть всякие общие действия, типа добавления элемента, их надо отрабатывать через общий вызов. С другой стороны, в индексе максимум фиксируются ключ (полуключ) и офсет добавленного элемента. Так что неизбежно надо задавать функцию ключа, но также видимо и полуключа (это потом). Кроме того, в некоторых случаях (View, Halfkey) и для сортировки и для поиска надо привлекать опорную последовательность. Так что надо ее восстановить. С опорной последовательностью есть такая "загвоздка", что на этапе формирования индекса, она может быть не достаточно вычислена. Попробую по-новой.

Итак, судя по интерфейсу IIndex, есть ссылка на опорную последовательность, есть одна или две функции, вычисляющие ключ, а если требуется и полуключ, используя задаваемую Hash-функцию. Индекс может быть полностью очищен Clear() и построен. Построение делается вызовом Build()

Похоже, достигнут определенный успех

10 млн. загружаются за 4.9 сек.
200 млн. грузятся за 110 сек.

### 20190114 08:14
Переехал в Москву, соответственно работаю на ноутбуке. Он слабее. Сейчас спрофилирую на предыдущем тесте. 
1 млн. записей загружается 3 сек., долго... 10 млн. - 23 сек. Буду иметь ввиду. Сейчас попробую сделать правильную выборку по ключу.

Сделал бинарный поиск, на 1 млн. элементов 2.4 сек. загрузка и 2.4 сек. выборка 10 тыс элементов. Сделал шкалу. На 1 млн. элементов загрузка 2.3 сек. 10 тыс. выборок 737 мс.

Провожу эксперименты на рабочем компьютере
1 млн. 0.5 сек., 174 / 10 тыс. 
10 млн. 5.3 сек., 202 / 10 тыс.
100 млн. 55 сек., 227 / 10 тыс.
200 млн. 105 сек., 223 / 10 тыс.
400 млн. 246 сек., 118 сек / 10 тыс.

### 20190127 10:09
Почти две недели не работал над проектом, кошмар!

Начну с того, что востановлю контекст из которого ушел. То есть, вспомню. Запустил последний вариант программы. Загрузка производится несколько дольше, но доступ - быстрее. Получившаяся пара:
10 млн. 8.5 сек., 181 мс. / 10 тыс.
без загрузки: 1 сек. (это подготовка шкалы), 217 / 10 тыс.

### 20190130 09:42
После разговора с Петей, решил кое-что записать. Главное, нужна качественная модель данных. Я ее уже пытался сформулировать, кое-что получилось, но до конца не сделал. 

Итак, модель данных должна включает в себя модель распределенного хранения, модель изменения, модели реализации. Модели реализации должны включать в себя и RDF-хранилище и реляционную базу данных. И чтобы все было совместимо.
Данные существуют в виде сегментов. Сегменты можно произвольно объединять, получая единое поле данных. Динамическая переконфигурация сегментов пока не рассматривается. Сегмент представляет собой множество записей. В частном случае RDF-хранилища сегмент может быть множеством триплетов. В этом случае, триплеты логически объединяются в записи через объединение по общему субъекту. У записи есть идентификатор, у записи может быть отметка времени mT ее создания. Если есть записи с одинаковым идентификатором, то верным является запись с более поздним mT. У записи может быть признак isnull, что означает уничтоженность содержимого записи, но не ее идентификатора. В случае RDF-хранилища, признак внедряется с помощью специального Datatype предиката f:isnull, при этом объект (пока) не существенен.
Если запись реализуется объектом, то имеется функция isnull(ob), дающая истину на isnull-объектах. Если записи реализуется таблицей, то (наверное) должна существовать колонка с булевкими значениями или как-то еще.

Еще есть отождествление. В OWL это задается триплетом <субъект> owl:sameAs <объект>. Будем пользоваться этой формой имея ввиду то, что идентификатор субъекта заменяется на идентификторо объекта. Это касается только сегмента, в котором появляется триплет с данным предикатом. Распространяется ли отнолшение на другие сегменты, непонятно. Наверное, распространяется, но это сделать может быть затруднительно. Идентификатор "субъекта" как бы "исчезает" из сегмента и не может быть снова определен. Все упоминания замененного идентификатора, как "снаружи", так и "изнутри", транслируются в заменяющий идентификатор. Логически, "оператор" sameAs эквивалентен физической замене идентификатора на другой во всех местах упоминания. Этих мест может быть только в субъектах и тогда эти определения становятся определениями других сущностей и взаимодействуют с другими определениями по общим правилам через mT. В одноуровневой RDF-сети, <id1> sameAs <id2> внедряется следующим образом: сначала выясняется нет ли записи с идентификатором id1 и какая у него временная отметка. Потом выясняется нет ли записи с id2 и какая у этой записи временная отметка. Потом физически уничтожается запись с более ранней отметкой, а во второй - изменяются, если надо, идентификаторы субъектов на id2. Потом изменяются все иденентификаторы id1, встречающиеся как объекты в триплетах, на id2. Хлопотно как-то... 

С отождествлением что-тоо плохо получается, по крайней мере, в распределенных системах. 

Рассмотрим семантику хранилища записей. У записи есть: идентификатор, отметка времени, свойство isnull, другие свойства по необходимости. Машина базы данных, по крайней мере логически может быть устроена как словарь:
Dictionary<string, object> db. Основной способ доступа к данным - запрос записи по ключу:
```
db.GetByKey(key); 
```
