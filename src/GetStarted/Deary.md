
### 20190326 07:40
Решил, что писать программу в одном решении, а вести дневник в другом - неудобно, попробую приближать записи дневника к 
разрабатываемым. 

Итак, вчера я вышел на решение поиска по объекту. По крайней мере, показываются результаты, соответствующие ожиданиям. 
Теперь надо довести их до правильных. Кажется, для этого надо сформулировать компаратор и запустить его в работу. Снова 
проговорю логику работы индекса, работающего по полуключу. Есть множество элементов, на элементах задана ключевая функция
и согласованный с ней компаратор. Компаратор более "тонкий" инстумент, т.е. если значения ключей элементов различаются, то
в этом же направлении различаются и значения компаратора, но не наоборот.

Индексная структура формируется как множество пар (ключ, элемент) или (ключ, офсет(элемента)). Эта индексная структура 
отсортирована по ключу и по компаратору. Поиск по образцу заключается в том, что предъявляется образец, по нему вычисляются
все элементы, которые с образцом совпадают по компаратору (а значит, и по ключу). Это можно делать в два этапа. 
Сначала выделить диапазон, в котором тот же ключ. А потом в этом диапазоне проивести линейный или бинартный поиск.

Есть еще один вопрос для будущего, как учесть в индексе динамику изменений опорной последовательности? Не получается вариант 
с добавляемыми парами (ключ-значение). Предположение заключается в том, что в качестве динамической части индексного построения,
можно использовать что-нибудь вроде SortedSet<T>. Вроде все там в порядке и даже компаратор можно задать, но не очевидна 
сложность добавления элементов. Соответственно, мы новые элементы можем добавлять, а потом с ними сравнивать.

Я еще подумал. Вроде SortedSet не подходит. Нужен какой-то отсортированный по компаратору список элементов. Причем сравнение 
элементов может быть и нулевым. Чтобы к списку можно было бы легко добавлять элементы, не изменяя его отсортированности. Далее,
задается (конкретный) предикат, согласованный с компаратором. Требуется найти все элементы, удовлетворяющие предикату. Как эта 
задача решается? Предикат - это функция. Пусть задается "уровень" - функция, которая < 0 на "левых" элементах, = 0 на 
"центральных" элементах и > 0 на правых. Центральные и есть решение задачи. 

Запутался в логике построения ключевого индекса IndexKey32CompImm. Причем запутался в том месте, когда начинает использоваться 
компаратор. Логика построения такова: есть опорная последовательность и именно к ней строится индекс. Для этого, определяется 
функция ключа и строится набор пар {ключ, офсет}. Дальше массив сортируется, первично - по ключу, вторично - по компаратору. 
Компаратор сравнивает два объекта, соответствующих элементам опорной последовательности. Причем сначала сравнение идет по ключу,
а вторично - с помощью компаратора. 

### 20190327 06:53
Так вчера и не "распутался". Есть проблемы с сортировкой по полуключу. Есть проблемы с выборкой по ключу. Итак, вернусь
к конструкции. Есть опорная последовательность элементов. На ней задан ключ (полуключ). Формируется последовательность пар 
ключ-офсет и сортируется по ключу, вторичная сортировка производится по компаратору. Компаратар задан на объектном представлении
элементов опорной последовательности. Поэтому объекты компарации формируются из пары ключ-офсет через чтение из опорной таблицы 
объекта по офсету. 

Теперь о выборке. Есть простая выборка по ключу. Это хорошо работает когда нет компаратора. Предположим, мы можем сформировать
элемент-образец. Тогда мы можем ставить задачу выборки всех элементов из опорной последовательности, "эквивалентых" образцу
по компарации. Но это - "точная" выюборка. Можно попробовать так и сделать. Алгоритм следующий. Мы образец используем в делении
отрезка пополам и, с помощью компаратора, находим ноль, одно или более решение, удовлетворяющее условию сравнения. Этим у меня
занимается некоторая рекурсивная процедура. Процедура есть, но она не сформирована для работы с компаратором. Попробую это 
изменить. 

Сейчас поменял реализацию для нахождения всех записей по заданному ключу. Выборка ускорилась почти в 2 раза! Теперь по субъекту
получаем 1000 запросов за 8 мс. (77 мс. на 10 тыс. запросов). Внимательно посмотрев, я выяснил, что сделал не то. Я вопосльзовался 
массивом пар, расположенным в ОЗУ. Надо применить другое решение. Кстати, хорошо бы иметь понятный и эффективный интерфейс. Для
отдельного инедекса, это взятие всех решений по образцу. Но по образцу чего? Самый "универсальный" вариант - по "образцу" элемента.
Или по образцу объекта (или субъекта), который позволяет что-то. Наверное, на уровне индексного построения, когда у нас есть
ключевая функция и компаратор, правильнее будет подавать псевдоэлемент. Попробую.

Вернул характеристики на 14 мс. за 1000 выборок. Это по субъекту. Теперь буду работать по выборке по объекту. Буду работать 
поэтапно. Сначала только по ключу: сортировка и выборка. Потом подключаем компаратор, опять же: сортировка и выборка. Потом 
выборка по "похожему" значению. 

### 20190329 06:37
Вчера засуетился, много чего сделал, а вот проектом не занимался. Как-то надо исправлять ситуацию, тем более, что просыпаясь, 
я думаю об алгоритмах и логике. "Открытием" последних дней оказалось осознание того, что словарь "ключ-офсет" не является 
универсальным решением для выстраивания динамической части индекса. Видно, что надо использовать что-то вроде SortedTree, но 
такого класса в стандартной библиотеке нет. Возможно, в динамической части индекса лучше оказаться от сортировки и пользоваться 
простым List<T> или LinkedList<T>. Или делать двухуровневую динамику, когда есть напр. SortedList и есть List. Правда SortedList
обладает двумя недостатками. Во-первых - это key-value коллекция. Во-вторых - ключи не могут повторяться, но наверное, это 
следствие первого свойства. 

Вернусь к тому, что надо делать прямо сейчас. Сейчас я работаю над полуключевым индексом. Первое действие, надо существенно 
ускорить сортировку. Идея естественная: сначала пары сортирую по ключу, потом для каждого ключа, идет выделение множества
элементов опорной последовательности и производится сортировка по компаратору. После этого, все пары переписываются из массива
в последовательность. Действую.

18:27

Еще утром сделал двухуровневую сортировку. Построение Build() индекса происходит за 900 мс. (1 млн. триплетов). Теперь 
буду пробовать правильно сделать поиск. 

### 20190330 08:15
Наконец, заработали решения построения индекса на основе ключа и полуключа. В тесте, индекс по субъекту строится на основе 
ключа, индекс по объекту строится на основе полуключа. Для 1 млн. триплетов, оба индекса строятся 4.3 сек., 1000 выборок 
для ключа выполняется 14 мс., для полуключа - 107 мс. В принципе, это не так плохо.

Попробую пропустить тесты на больших размерах данных. 

1 млн. 4.3 сек., 14, 107
10 млн. 47 сек., 27, 151
100 млн. - Ушел в свопинг при загрузке данных (компьютер 8 Гб ОЗУ)

На работе (16 Гб ОЗУ)
1 млн. 5.5 сек., 19, 153
10 млн. 58 сек., 29, 206
100 млн. 755 сек., 19 сек., 279 (ОЗУ использовалась на пределе, странный результат по выборкам по субъекту), диск 3.7 Гб.
100 млн. без загрузки (Refresh) 11 сек., 19, 224

Есть еще режимы, которые надо бы проверить. Первое использование хеш-функции в качестве полуключа. И второе - использование 
функции уровня. Функция уровня задается на элементах опорной последовательности и принимает значения (отрицательное, 0, 
положительное). Выборка формулируется как выборка всех элементов, которые на этой функции равны нулю. Надо попробовать.

Делаю тестовую программу 15. Вернулся к последовательности персон:
```
PType tp_person = new PTypeRecord(
    new NamedType("id", new PType(PTypeEnumeration.integer)),
    new NamedType("name", new PType(PTypeEnumeration.sstring)),
    new NamedType("years", new PType(PTypeEnumeration.real)));
```
Организовал таблицу UniversalSequenceBase, сделал ввод. Миллион записей загружался 300 мс. Теперь добавляю индекс. 
Для начала - на идентификатор. Загрузка стала дольше - 635. Теперь вычислю тестовый запрос. Тестовый запрос правильный,
время выполнения 1000 запросов по идентификатору 12 мс. Испытание на большие размеры
1 млн. load 632, 12
10 млн. load 6.4 сек, 13
100 млн. load 64 сек, 14 
100 млн. без загрузки refresh 900 сек, 14 

Теперь сделаю другие индексы. Более простое решение - исплользование хеш-функции в качестве полуключа. Метод имеет тот 
недостаток, что нарушается монотонность. В частности, это означает, что не видно возможности делать выборки по близким 
именам. Итак, надо написать ключ, далее - посмотрим. 

1 млн. load 980, 19.  total=1003
10 млн. load 10 сек., 20.  total=1076-1100
100 млн. load 102 сек., 22.  total=1300

В общем, все по теории. Но здесь я получаю все решения, хеш-ключ которых, совпадает с хеш-ключом образца. В принципе, 
есть два решения задачи выборки по ключевой функции. Первое решение - фильтровать промежуточный набор и доводить его
до нужного. Второе решение - воспользоваться всем "могуществом" двойной сортировки, заложенной в IndexKey32CompImm.
При этом, мы потеряем что-то. Посмотрю как это будет выглядеть в на этом примере. 

Я проделал все манипуляции "в лоб" - соорудил индекс, там указал функцию (хеш)ключа и компаратор. По реализованным правилам,
если есть компаратор, то шкала не создается. Отсюда и более значительные времена обработки запросов. Теперь 10 млн. персон
обрабатывается: load 40 сек., 1000 выборок по имени 83 мс.

### 20190331 03:49
Что-то не спится... Попробую "наработать" желание поспать.

Вывод из предыдущих построений: надо сохранить обе возможности для получения решения - и фильтрацию после выборки по 
хеш-ключу и бинарный поиск по полному ключу. Теперь надо разобраться с поиском "близких" значений. Сортировку общего плана
я сделал в IndexViewImm. Но она трудозатратна. Это потому, что либо весь массив последовательности долже быть загружен в ОЗУ,
либо будет многократное обращение за элементами, лежащими на диске. 

Я применил IndexViewImm - он основан на ОЗУ и работает быстро. 19 мс. на 1000 выборок. Класс надо бы пределать, но сейчас это 
не так важно. Думаю поработать над этим классом и приведением его в норму. Для этого, для начала, нужно сделать работу с диском.

Кстати, пришла в голову новая идея. Делаю кодирование исходя из статистики. Написал код буквы, потом следующая буква 
определяется следующим кодом. Как-то не так сформулировал. Нам нужно кодировать цепочку символов. Можно использовать частотное 
кодирование, можно - более сложное. Частотное кодирование можно брать из статистики текущего варианта текстов. 

Итак, делаю "чистый" стенд в котром будет загрузка последовательности и вычисление только view-индекса. Итак, "чистая" загрузка
3280 - собственно загрузка. Вычисления - 13 мс. на 1 тыс. запросов. 
1 млн. load 3.3 сек., 1000run 13 мс.

Что-то странным образом изменилось и теперь вычисления выполняются 5 мс. на 1 тыс. запросов. Это на массивах в ОЗУ. Переношу 
вычисления на индексную последовательность. Возьму фрагмент в базовом ключевом индексе.

Вроде получилось! Единичная проверка прошла успешно. Время выполнения 1 тыс. запросов 130 мс. Неплохо!.. Но можно сделать лучше.
Есть такая идея: сделать "редкий" массив значений. Сначала находим интервал в массиве, потом в интервале ищем решение. Интервал,
правда, может объединить несколько отрезков. Как всегда, нас интересует количество обращений к диску при поиске. При бинарном 
поиске, для одного миллиона мы имеем приблизительно 20 обращений. Если сократим интервал до 16-ти, будет 4. Как-то так... Можно 
даже попробовать. 

Проделал некоторый эксперимент. Заменил бинарный поиск в массиве на прямой поиск типа:
```
    var res = elements
        .SkipWhile(ob => comp.Compare(ob, obj) < 0)
        .TakeWhile(ob => comp.Compare(ob, obj) == 0);
```
Поиск работал очень долго - 63 сек. на 1 тыс. запросов. Это более, чем в 10 тыс. раз медленнее, чем с использованием дихотомии.
Попробую добавить дихотомию. Добавил дихотомию. И даже Turple. Теперь на массиве, поиск диапазона выполняется 19-20 мс. на 
тысячу. Системный бинарный поиск работает быстрее, но здесь несколько иная постановка и я не могу им воспользоваться. 
Постановка - найти (минимальный) диапазон в массиве elements такой что первая точка <=0, а следующая за последней точка 
- точно больше нуля. Нет нуля, нет искомой точки... Все же результат неплох. Попробую применить его. 

### 20190401 05:11
День математика, дурака, геолога, Ура!!!

Исправил кое-какие ошибки и... получилось!  
1 млн. load 3.9 сек., 1000run 37 мс.

Это не 13 мс., но и не 130... 

Сейчас подбирал Nfactor. Остановился на 40. Скорость получается несколько хуже - 42-43, но объем использования ОЗУ существенно
меньше. Диапазон высоких скоростей 16-20.

Если делать без загрузки, получается время 150-170 мс. на тыс. Это потому, что Refresh не делает этот массив. 

07:55

Оказывается, я забыл при измерениях сменить режис с отладочного на нормальный. Сменил, результаты 3.4 сек., 38 / 1000

Последний решительный шаг в том, чтобы выполлнять сортировку по частям. Думаю, сделать это "тупо". Сначала делается равномерное
расположение последовательности офсетов. Потом, мы делаем процедуру делания копии части последовательности. Потом делаем
выборку массива объектов и массива офсетов и сортировку по компаратору. Потом начинаем делать сливание массивов с использованием
сравнения. 

19:23

Возвращаюсь к разработке. 

Сделал первую часть: создаю последовательность офсетов, определяю рекурсивный метод 
```
Bld(long start_ind, long number)
```
который сортирует отрезок офсетов по значению объектов. Потом применяю функцию и потом вычисляю разреженный массив. Все
это заработало в режиме, когда используется только оперативная память. Работает с теми же скоростями, что и раньше. 
```
1 млн. load 4.3 сек., 1000run 40 мс.
10 млн. load 47.8 сек., 1000run 61 мс.
20 млн. load 108 сек., 1000run 85 мс.
40 млн. load 500 сек., 1000run 474 мс. - свопинг
```

### 20190402 15:15
Сделал рекурсивную часть Bld. Но пока не работает. Начал отладку, похоже там две ошибки. Буду отлаживать отключив 
прореживание. 

### 20190403 09:51
Исправил ошибки, их оказалось несколько больше двух. Теперь запустил на большой тест, который засерит характеристики на
100 млн. элементов. Использование памяти пока ведет себя пристойно - потихоньку добралось до 7 Гб., теперь уменшилось до 5,
на задачу не досчитала. 
```
1 млн. load 4.3 сек., 1000run 38 мс. (131 без прореживания)
10 млн. load 47 сек., 1000run 60 мс. (171 без прореживания)
10 млн. noload 1.4 сек., 1000run 72 мс.
100 млн. load 1590 сек., 1000run 292 мс.
100 млн. noload 956 мс., 1000run 218 мс.

На 16 Гб ОЗУ:
Поставил объем на 50 млн. единиц
100 млн. load 994 сек., 1000run 189 мс.
100 млн. noload 17 сек., 1000run 195 мс.
200 млн. load 2491 сек., 1000run 250 мс.
200 млн. noload 34 сек., 1000run 243 мс.
400 млн. load 6400 сек., 1000run 349 мс.
400 млн. noload 70 сек., 1000run 311 мс.
```
### 20190405 20:26
Теперь я мысленно нахожусь уже в реализации хранилища триплетов или хранилища записей. Как-то я не определился
в этом вопросе. Хранилище записей проработано неплохо, в частности понятны механизмы добавления, изменения и 
уничтожения. Запись может быть довольно произвольной структурой, Напр. такой:
```
REC = { id: string, fields: { prop: string, val: VALUE }, directs: { prop: string, direct: string } };
VALUE =  empty^ none,
	str^ string,
	langstring^ { lang: string, str: string};
```
Ну или как-то аналогично. К записям можно добавить отметку времени и признак deleted, после этого реализовать 
оговоренную логику слабой динамики. Возникает вопрос с обратными ссылками. 

Другой подход давно обдуман. В нем основной объект последовательности - триплет. Теперь к триплету "приделываем"
логику редактирования: временной маркер и признак уничтоженности. И делаем два (!) индекса spo и op (может ops).
Для качественного хеширования, берем 64-разрядное кодирование. Кодируем строки uri 63-разрядным хешем. А ObjectVariants
кодируем частями: вид - 1 бит, в случае uri, остальная часть - хеш-код. Если значение, то вариант значения. Базовые
варианты: строка, целое, дата, (языковый) текст. Может еще что-то. Spo Хеш-код триплета может выглядеть как: 32 разряда
Субъект, 8 разрядов предикат, 24 разряда объект. 

А если попроще и в рамках 32-х разрядов? Триплеты в проработанном варианте { uri, uri, OVars }. А индексы выстраивать 
неполные. Только по субъекту и только по объекту. По субъекту - просто. По объекту, я прикидывал ключ, состоящий из знака,
как признака Uri/OV. Потом идет целое или хеш целого. По другому варианту, это может быть хеш строки. 

### 20190407 05:52
Я подбираюсь к комплексному решению задач архивного комплекса. Архивного комплекса как распределенной информационной
системы. Можно назвать эту систему "островки" или "архипелаг". Второе - с ассоциацией на архивность. 

Пусть есть множество кассет. Причем как единичных, так и сгруппированных. Кассета, это множество (мультимедиа) документов
и фрагменты базы данных. База данных описывает документы этой группы касет или наборы сущностей, связаных или не связанных
хранящимися в кассетах документах. База данных хранится в формате модифицированного Turtle. Не знаю как насчет пространств
имен, но формат вполне удобен и компактен. Все его возможности мне не нужны, но простая компактизация с использованием 
разделителей ';' и ',' хорошо подходят для моих целей. А цель в том, чтобы изображать целостную запись и чтобы запись не
"расползалась" по тексту и по файлам. Нужен транслятор, но вроде больших проблем нет. 

Онтологию надо применять BONE. Есть некоторые системные расширения: владелец owner, отметка времени mT, isnull или deleted.

А нет ли проблемы в том, что я назначаю атомами триплеты, а транзакции выполняются с записями? Наверное нет, если ...

Итак, рассуждаю. Пусть имеются записи. Во внешнем представлении записи, это набор триплетов, имеющих общие субъекты и имеющие 
общую оболочку. Набор записей составляет один сегмент. Имеются e-сегменты, e это external, и имеются d-сегменты, d - data. 
Множество e-сегментов может быть преобразовано в d-сегмент, но не наоборот. Запись характеризуется идентификатором субъекта,
составляющих ее триплетов. Информационное поле (база данных) состоит из триплетов, составляющих объединяемые записи. Записи
с одинаковым идентификатором конкурируют между собой. "выигравшей" записью считается запись, имеющая более позднюю 
временную отметку. Отсутствие временной отметки трактуется как "очень давно" и любая запись с тем же идентификатором "выигрывает"
у такой записи. В e-сегментах может быть по нескольку экземпляров тождественных записей, в d-сегментах - только один. Отметка
времени - это триплет
```
<subj> b:mT "DateTime" .
```
Еще один служебный триплет - "обнуляет" триплет
```
<subj> b:isnull b:null .
```
Кажется, такая запись избыточна, можно заменить на что-то предикат или убрать (заменить на значение) объект. Но пока будем
действовать указанным образом. Самым сложным в общей семантике записей, является 
```
<subj> owl:sameAs <obj> .
```
И означает она, что все вхождения данного субъекта следует заменить на obj.  

20190408 06:37
Эквивалентность реализовывается с помощью кодирования. Это означает, что используемые uri кодируются, напр. целыми числами,
появляется таблица имен. В таблице имен проставляются одинаковые коды эквивалентным идентификатрам. Такая таблица имен требует
дополнительного построения и не слишком удобна в использовании. Последнее - поскольку ввод осуществляется за два прохода, первый
строит таблицу имен, второй - использует для собственно ввода. Итак, какая требуется дополнительная структура?

Сейчас вспоминал как это реализовано в нынешней версии. Реализовано не очень экономно. Выстраивается table_ri - словарь, имеющий
по входу на КАЖДЫЙ идентификатор, а основным значением словарного определения является список всех эквивалентынх идентификаторов 
данной цепочки. Поскольку ввод идет в два прохода, можно словарь уменьшить до размера только сливаемых идентификторов. Для этого
можно обрабатывать только указания эквивалентности. (Или ввести битовую шкалу?). 

Я проверил, действительно таблица table_ri выполнена неэкономно. А как нужно? Сканируются записи. Если в очередной записи
есть отождествление, то только в этом случае производится коррекция таблицы. Коррекция заключается в том, что проверяется
наличие обоих идентификаторов в таблице переименований. Если идентификатора нет, то вход для него заводится. Если есть, то
используется имеющийся вход. По обоим входам должна быть записана один и тот же список. Причем для других эквивалентных входов
список скорректируется автоматически. Это вообще возможно?  

Я тщательно подумал. Конструкция решения следующая. В словарь попадают только идентификаторы, которые отождествляются. Значение 
в словаре это элемент однонаправленного (двунаправленного?) списка. Ссылка null - конец цепочки. Пусть A и B идентификаторы
отношения 
```
<subj> owl:sameAs <obj> .
```
Мы такое отношение анализируем в контексте уже накопленных данных в словаре
```
Dictionary<string, Node> nodes = ...
```
Пусть A и B отсутствуют в словаре. Тогда создадим два узла и два входа в словарь, а узлу A прямую ссылку на следующий 
установим на узел B. В появляющихся цепочках последний узел (у которого нет ссылки на следующий), является "оригиналом",
т.е. узлом, идентификатор которого предплагается к использованию вместо всех элементов цепочки. Если A присутствует в словаре,
а B отсутствует. Тогда к последнему элементу цепочки A "приделываем" узел, образованный от элемента B. Если наоборот, B имеется,
а A отсутствует. Тогда цепочку B удлиняем с головы. Если есть оба элемента и есть их цепочки, то к последнему элементу цепочки
A прикрепляем цепочку B. Вот здесь и кроется "засада". Дело в том, что от элемента B у нас нет возможности найти первый элемент 
его цепочки. Выход понятен - сделать двунаправленный список. Ну нужен ли нам первый элемент цепочки? Мы прикрепляем цепочку
A к любому узлу B и этого достаточно для того, чтобы выйти к последнему. Получается дерево с корнем в последнем узле. Если надо
распространить что-то на все узлы цепочки, то нужны двунаправленные связи, а добраться до корня, можно и по однонаправленным. 

### 20190409 08:30
С утра думал о том, что надо бы активировать конференционную и публикационную активность. Придумал то, что могу подать доклад
на Ершовскую конференцию. Придумал название, попробую его воспроизвести. "Технологическая цепочка для локального хранилища
документов и данных". Как-то так... 

Написал несколько больше одной страницы, завтра продолжу. 

Главная неразрешимость моих размышлений - это "языковый барьер", т.е. как эффективно представлять langString. Для самих 
значений, это сделать несложно, но экономномная хеш-функция не получается. Более того, непоянно как организовывать стравнение
языковых строк. "en" и "en-US" это одно пространство? Или та часть английского алфавита, которая совпадает с французским
может быть использована для поиска? А может языковый тег вообще непричем в задаче поиска? Почему не искать по char?

### 20190411 20:08
По "языковому барьеру" идея такова: мы будем использовать англо-русские символы. Т.е. стандартные английские и добавленные
русские. Никакого языкового спецификатора на стадии определения похожести текста на образец. Как-то так...

### 20190412 05:42
День космонавтики! Какие героические годы были 50-е и 60-е. И почему сейчас Россия не может развиваться аналогично?..

Честно говоря, я что-то застрял на отвлечении на Поляр. В принципе, я хотел сделать индексы, я их сделал. Последний индекс, 
которым я занимался - IndexViewImm. Все вроде неплохо, но есть некоторая проблема: поиск в режиме студии выполняется за 39 мс.
на 1 тыс запросов, а в консоли - 97 мс. на 1 тыс. Это в 2.5 раза! Непонятно...

Сейчас провел несколько экспериментов. Так и не разобрался... Ну да ладно, это не главное.

Теперь вспоминаю, что я хотел сделать хранилище триплетов, более того, что-то уже делал. Попробую снова, но теперь под 16-м
проектом. А начало кода возьму из 14-го. 

### 20190413 09:49
Я готовлюсь к тому, чтобы сделать и испытать хранилище триплетов. И мне все не дает покоя вопрос с реализацией обратного
отношения. Я вот подумал, что ыполне может быть два и более родственных индекса. Например, наряду с индексом по значению,
может быть индекс по коду uri. И этот индекс может быть довольно эффективным. Ранее, я всегда предполагал, что число элементов
в простом индексе совпадает с числом записей в опорной таблице. Но откуда это следует, и где это используется? Потом выяснилось,
что для слабой динамики это не так, что там индекс достраивается каким-то динамическим сооружением. Итак, вопрос: как сделать 
индекс, с числом элементов, не совпадающим с числом опорных элементов. Вроде все просто: если ключевая функция выдает null, то
не делать индексную точку. Но можно и по-другому: при индексировании передавать массив ключей для данной записи. Технически, 
это будет векторный индекс или как его можно еще назвать "словарный индекс". Попробую пойти этим путем, тем более, что векторный
индекс всяк нужен в комплекте. 

Для тестирования, добавлю ссылку parent в персональную запись и тест будет выдавать детей персонажа. 

Итак, тестирование прошло. Временные характеристики хорошие. для 500 тыс. персон прямые запросы по клиючу выполнялись 18 мс. на
1000, обратные 13 мс. / 1000

- объем, загрузка, прямые, обратные
- 500 тыс., 1424, 18, 13
- 5 млн., 14.5 сек., 18, 13
- 50 млн., 161 сек., 43 сек., 13 сек.

### 20190414 07:41
Идея делать индексы не под абстрактную потребность, а под конкретную, выглядит интересной. Обратный объектный индекс уже 
получился эффективным. Еще эфективнее будет сделать отдельные индексы под типизацию и под обратные отношения. Самое забавное, 
что если не делать пересечений в индексируемых записях, то объема индексных таблиц это не увеличивает. Некоторую настороженность 
подход вызывает из-за кодирования. Но может, все не так плохо. Мы сначала делаем ввод триплетов. При этом, выполняется 
кодирование. После начального ввода, при должной технологии, уже некоторые uri определятся, так что можно их закладывать в 
функции. Можно и по-другому - делать ключевую функцию на строковом представлении триплета. Но это возможно только если функция
используется только перед сортировкой. 

Я под утро продумал устройство хранилища триплетов и у меня теперь "чешутся руки" это попробовать. Осталось не так много: сделать
хорошую таблицу имен и слабую динамику. Подумаю над таблицей имен. Проще всего таблицу имен каждый раз делать заново. Вот есть 
хранилище триплетов. Там сначала ничего нет. Кроме пустой таблицы имен и пустой последовательности. Технически, надо бы иметь
возможность внести в таблицу имен несколько констант. А потом вносим триплеты. Потом определяем функции ключей для индексных
построений. Потом делаем индексы, протом запускаем слабую динамику. Все это я уже проделывал, теперь надо повторить. Причем
повторить максимально просто, прозрачно, эффективно. 

Попробую сделать хранилище путем втягивания в работающее решение других функциональностей. 

Проблема, надеюсь маленькая, возникла при реализации таблицы имен. Для таблицы имен номер элемента в последовательности и есть
код элементы. Но не хранить же его, когда он зафиксирован в таблице офсетов... Или хранить? Попробую порассуждать. Минимальный 
вариант индексных построений следующий: table - последоватльность строк, str_offsets - последовательность офсетов предыдущей 
таблицы, name_index - индексное построение из ключей и офсетов, отсортированных по ключам. В качестве ключей используется 
хеш-код строки. Когда есть строка-образец, проводится поиск множества совпадающих с хеш-кодами пар. Здесь есть пара проблем.
Одна проблема в том, что по значению офсета еще надо проверяь то, что элемент совпадает с искомой строки. Вторая та, что по 
офсету строки еще надо поискать код, это что, надо снова запускать бинарный поиск? Отказываться от последовательности офсетов
не выгодно, потому что по коду легко находить строку. Похоже, естественным решением является сделать опорную последовательность
в виде последовательности пар {код, строка}. Буду делать. 

Что-то сделал и засомневался. Надо отбросить сомнения и действовать...

### 20190415 05:44
Начал доделывать таблицу имен и двигаться в сторону комплексного решения по хранилищу триплетов. Теперь мне понадобится тест 
"фототека". Написал генерацию персон, пока я не загружаю данные, только кодирую триплеты. Скорость неплохая: для 4 млн. персон
триплеты кодируются 9.5 сек. Из них собственно кодирование выполняется 7 сек. Теперь проверю что получилось. 

Что-то я изменил. Теперь 40 млн. персон загружаются (кодируются) 121 сек и строится индекс 152 сек. Проблема в том, как
корректно организовать работу по подключению к данным, по загрузке, по построению. Можно Build выполянть периодически,
по переполнению лимита для словаря, в конце работы, в начале работы. Причем можно посмотреть на полноту вычисленного 
индекса и тогда принимать решение о построении индексной последовательности или словаря. Индексная последовательность 
может быть также разбита на большую и малую. Это замедлит доступ, но ускорит старт.

Провел эксперимент с тестом Фототека на размере 4 млн. (100 млн. триплетов). Так вот, загрузка производилась 112+110 сек.

Я хотел подумать насчет переходных процессов в идексах, снабженных слабой динамикой. Дело в том, что изменения в индексах 
какое-то время накапливаются в динамических структурах. Предположим, выключилось питание. После включения, мы имеем 
рассогласование, поскольку не восстанавливали динамическую составляющую. Есть три способа решения задачи: восстанавливать 
динамическую структуру, обнулять индекс и строить по-новому, делать второе в фоновом режиме. Похоже, что для того, чтобы 
корректно работать с динасическими индексами, в индекс надо добавить два поля: номер следующей записи опорной 
последовательности и офсет следующей записи там же. По этому номеру можно произвести стравнение с количеством элементов в
опорной последовательности и создать динамическую структуру. Либо сформировать новый вариант индекса. 

Эти соображения коррелируют с некоторым общим поведением индексов. Индексы порождаются, индексы присоединяются, строятся, 
инициируются, элементы в опорную таблицу помещаются. Пока все это богатство не описано, буду продолжать строить экспериментальное
хранилище. 

### 20190416 08:03
Ночью и частично ранним утром запистил тест Фототека. Вроде работает, хотя надо бы убедиться в том, что делается именно
то, что хотелось. 

Протестирую полученное решение
```
40 тыс. 238
400 тыс. 274
2 млн. загр. 700 сек., 316 / 1000 !!!
4 млн. загр. 490 сек., 347 сек. / 1000
```
Расчеты показывают, что в решении есть дефекты. В частности, f6.bin остался незаполненным. Кроме того, без загрузки на 2
млн. 1000 запросов выполняются 746 сек! Видимо, это свидетельствует о том, что разогрев работает плохо. 

Действительно, разогрев не работал. Включил, получилось нормально. Для фактора 400 тыс., разогрев выполняется 11 сек., 
выборки 288. Тогда как в полном варианте, загрузка 19 сек., выборка 284. Что-то слабовато работает разогрев...

Появилась идея: разбить разогрев на 2 этапа. 1-й этап обязательный, там должны выполняться обновление массивов, использование
которых критично для достижения высоких значений производительности. 2-й этап необязательный или выполняемый в фоновом 
режиме. Это разогрев (очень) больших файлов. Причем таких, которые нужны для "однократного" доступа в рамках запроса. 

### 20190417 09:42
Главное - двигаться! Поставил задачу сделать простое хранилище триплетов, надо выполнять. Собственно 2 индекса я уже сделал:
прямой и обратный, теперь надо сделать индекс на имена. Я уже такой делал, но все же надо еще раз подумать. И сделать! Посмотрю 
код.

В хранилище есть последовательность объектов типа tp_triple, причем триплет состоит из полей субъекта, предиката и объекта. 
Субъект и предикат - простые строки uri, объект - (объектный) вариант iri, строки, целого, даты и языковой строки. Как 
использовать триплеты, это мы еще подумаем. Но в хранилище есть еще три индекса. Еще все uri в триплетах кодируются с помощью
таблицы имен. Еще есть три индекса. Один дает возможность выбирать объекты триплетов по полю субъекта, второй - по значению
объектного объекта, третий индекс соответствует некоторым строкам в "строковом" объекте. Реально, я собираюсь это поле
использовать для поиска по name, причем поиска по совпадению начальной части имени. 

Вообще, построение индекса под схему и под данные, может оказаться "новым словом" в проблематике баз данных. Итак, делаю 
третий индекс и проверяю его. 

Я подумал, что можно довольно сильно искажать локальный алфавит, применяемый для формирования хеш-ключа. Например, мы можем
взять русские (32 буквы) и латинские (24) буквы и получить алфавит, кодируемый 6 символами. 5 букв будет укладываться в
одинарное целое и еще 2 бита остается. При этом, возможна разная стратегия реакции на отсутствующий в "алфавите" символ. Можно
его просто пропускать, а можно вместо него ставить какой-то символ, напр. '*'. Можно еще проредить буковки, напр. вместо 
латинских, использовать только какую-то латинскую букву, можно выбросить (скорее - заменить) гласные или редко применяемые буквы
и т.д. и т.п. Все это возможно тогда, когда a = b влечет code(a) = code(b), а значит, мы не пропустим равенства если равны 
кодирования. Еще надо иметь неравенство треугольника. Пусть студенты подумают. 

Теперь надо вернуться к каноническому индексу, которым у нас является IndexKey32CompImm. Сейчас он недоделан, но кажется,
его вполне можно доделать. Как устроен (этот) индекс? В целом, это последовательность пар: {ключ, офсет}. Каждая пара 
порождена от элемента, начинающегося с указанного офсета. Важное новшество: от одного элемента может появиться несколько
пар. У этих пар общий офсет, но разные ключи. Итак, индекс первично определяется ключевой функцией, которая порождает поток
(ноль, один, два, много...) ключей. Офсет берется из вычисления. Пары сортируются по ключам, при равенстве ключей, для 
сортировки используется компаратор. Компаратор может отсутствовать (быть нулевым), тогда есть задача сортировки упрощается
и задача выборки формулируется как выборка по ключу. Теперь пусть компаратор ненулевой. Тогда множество пар, распавшееся 
на непересекающиеся подмножества с одинаковым ключевым значением, дополнительно сортируются по компаратору.

При наличии компаратора, какая задача решается при выборке данных? В этом месте похоже не удастся обойтись без 
(поискового) экземпляра элемента опорной последовательности. Вообще-то это довольно странно, потому что такой элемент, как
правило, даже в принципе не мог бы существовать. А так, при наличии "поискового экземпляра", требуется найти все элементы 
опорной последовательности, у которых и ключ совпадает с ключем образца и компаратор дает ноль. В некоторых случаях, выборки 
подчиняются другому правилу - "правилу уровня". Это когда задается на элементах функция уровня. Это происходит, когда ищутся
значения "близкие" какому-то образцу. Например для лексикографического упорядочивания, поиск "близкого" значения может 
реализовываться через фукцию уровня 
```
public int LevelFunc(obj, string sample) 
{ 
	string s = ....; // значение строки, взятое из объекта
	int cmp = string.Compare(s, 0, sample, 0, sample.Length, true);
	return cmp;
}
```
Поиск должен выдавать все элементы опорной последовательности, на которых LevelFunc выдает ноль. Согласованность этой 
функции с функцией ключа и компаратором должна определяться разработчиком. Это еще в дополнение к тому, что когда определяются
"близкие" значения, то нужна согласованность еще и с ключевой функцией. 

### 20190418 08:03
Попробую заложить описанные возможности в упомянутый класс. Только переименую его на полное название: IndexKey32CompImmutable.

### 20190420 06:28
Сделал новый класс, но изрядно помучался с отладкой.

Итак, в классе IndexKey32Immutable есть: конструктор класса, Clear, Count, Build, Refresh. Суть их в том, чтобы построить 
или активировать индекс. Индекс задается двумя определениями. Во-первых, это функция KeysFunc, преобразующая объектное
представление элементов опорной последовательности, во-вторых, возможно задание компаратора, сравнивающего эти элементы. 
Логика индексного построения в том, что оно 1) выделяет из множества элементов какие-то; 2) формирует систему поиска элементов, 
попавших в выделение. Элементы выделяются тем, что ключевая функция имеет множественный результат. Если формируется пустое
множество, то по данному индексу элемент недоступен. Если непустое, то элемент доступен через каждое значение ключа, формируемое
функцией. Что значит, что доступен через значение ключа? Пары {ключ, элемент} выстраиваются в какую-то структуру, по значениям
ключа, напр. сортируются. Напомню, что в данном индексе ключ - 32-разрядное целое. 

Какую задачу решают индексы? Задачу эффективного выхода на подмножества элементов через задание каких-то значений. 
Итак, основной способ упорядочивания доступа к элементам через индекс, выстраивание ключей. В данном случае, 32-разрядных целых.
Ключи можно отсортировать и можно обеспечить выборку по конкретному ключу. Конкреный ключ получается применением ключевой
функции к элементам опорнорй последовательности. Независимая генерация поискового ключа лежит на ответственности разработчика.

Типовые способы применения IndexKey32CompImmutable. Первый - уникальная индентификация целочисленным идентификатором. Выборка по 
ключу решает проблему. Выборка по ключу выполеняется методом:
```
	public IEnumerable<object> GetAllByKey(int key);
```
Второй - строковая идентификация. Тогда в ключевой функции применяем хеш-функцию и при выборке применяем
ее же. 

Возникла проблема. Что-то "утвержденный" индекс не демонстрирует нужных характеристик. Пытаюсь найти проблему. 

Старый вариант: Загрузка 856, запросы 14 / 1000
Новый вариант: загрузка 640, запросы 72

Это что-то грубое. Посмотрю код. Нашел, исправил, работает хорошо.  

Новый вариант: загрузка 632, запросы 12-13
10 млн. 6.5 сек., 14
100 млн. 72 сек., 20 сек.
100 млн. без загрузки Refresh 826 сек., 14 сек. (из холодного состояния, Refresh выполянется 30 сек.)

Следующее испытание строковая идентификация. Есть строки, требуется сделать индекс, который бы эффективно работал бы
по ключу. Есть два способа для решения: без привлечения вторичной сортировки и с привлечением. Попробую первый вариант. 
```
    var os = str_index.GetAllByKey(Hashfunctions.HashRot13("" + k))
        .Where(ob => (string)((object[])ob)[1] == "" + k); 
```
Такой вариант работает очень хорошо. Но надо иметь ввиду, что наложений при таких характеристиках задачи чрезвычайно 
мало. Мои измерения показали 0.1-0.3%. Скорости получились:
1 млн. 650, 20


Теперь попробую другой вариант.

### 20190421 06:30
Другой вариант не получился, потому что я не согласовал сортировку по значению хеш-функции и детальную сортировку. Такое 
согласование можно сделать используя  int First4chars(string s). Правда там есть нюансы, связанные с сортировкой русского
языка, но надо эти нюансы преодолевать.

1 млн. 3.9 сек., 61
10 млн. 38 сек., 100
50 млн. 223 сек., 98

Результаты выглядят хорошими. Можно возвращаться к проектированию хранилища триплетов.

Итак, надо наметить план. Сейчас пройдусь по коду 16-й программы, сделаю изменения в соотвествии с (рекомендациями) Main17.
Надо довести все это до более или менее рабочего варианта. Пока без слабой динамики.

Сразу буду отмечать что надо будет сделать позже. 

1) Таблицу имен надо полностью "втянуть" в хранилище.
2) Объединить в интерфейс общие действия с индексами - построение, обновление и т.д.
3) Сделатиь слабую динамику

Пол дня искал ошибку. Нашел, исправил, появилась еще одна. Еще пол дня искал... Теперь могу провести некоторый контрольный 
расчет. Итак, загрузка, выборка по субъекту, выборка по имени

40 тыс. 3.8 сек., 249, 287
400 тыс. 39 сек., 297, 2625 (надо поработать!)
4 млн. 612 сек., 196 сек., 27 сек.
4 млн. без загрузки 52 сек., 329, 28 сек., объем файлов базы данных 4.64 Гб.

Пора позаниматься ответственными делами, отключаюсь...

### 20190422 06:20
Не все меня устраивает из проделанного. Для ориентировки, решил проделать эксперименты с View-индексом IndexViewImm.
По использованию диска, он экономный и как-то мне удалось решить основные проблемы, связанные с ним. Запустил, получил:
1 млн. 4.5 сек, 39
10 млн. 46 сек., 42
20 млн. 98 сек., 44
40 млн. 210 сек., 46
60 млн. 330 сек., 51
80 млн. 473 сек., 134. Без загрузки 11 сек., 47
100 млн. 623 сек., 47
150 млн. 1072 сек., 108. Без загрузки 19.5 сек., 47

 












 












