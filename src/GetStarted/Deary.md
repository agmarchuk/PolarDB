
### 20190326 07:40
Решил, что писать программу в одном решении, а вести дневник в другом - неудобно, попробую приближать записи дневника к 
разрабатываемым. 

Итак, вчера я вышел на решение поиска по объекту. По крайней мере, показываются результаты, соответствующие ожиданиям. 
Теперь надо довести их до правильных. Кажется, для этого надо сформулировать компаратор и запустить его в работу. Снова 
проговорю логику работы индекса, работающего по полуключу. Есть множество элементов, на элементах задана ключевая функция
и согласованный с ней компаратор. Компаратор более "тонкий" инстумент, т.е. если значения ключей элементов различаются, то
в этом же направлении различаются и значения компаратора, но не наоборот.

Индексная структура формируется как множество пар (ключ, элемент) или (ключ, офсет(элемента)). Эта индексная структура 
отсортирована по ключу и по компаратору. Поиск по образцу заключается в том, что предъявляется образец, по нему вычисляются
все элементы, которые с образцом совпадают по компаратору (а значит, и по ключу). Это можно делать в два этапа. 
Сначала выделить диапазон, в котором тот же ключ. А потом в этом диапазоне проивести линейный или бинартный поиск.

Есть еще один вопрос для будущего, как учесть в индексе динамику изменений опорной последовательности? Не получается вариант 
с добавляемыми парами (ключ-значение). Предположение заключается в том, что в качестве динамической части индексного построения,
можно использовать что-нибудь вроде SortedSet<T>. Вроде все там в порядке и даже компаратор можно задать, но не очевидна 
сложность добавления элементов. Соответственно, мы новые элементы можем добавлять, а потом с ними сравнивать.

Я еще подумал. Вроде SortedSet не подходит. Нужен какой-то отсортированный по компаратору список элементов. Причем сравнение 
элементов может быть и нулевым. Чтобы к списку можно было бы легко добавлять элементы, не изменяя его отсортированности. Далее,
задается (конкретный) предикат, согласованный с компаратором. Требуется найти все элементы, удовлетворяющие предикату. Как эта 
задача решается? Предикат - это функция. Пусть задается "уровень" - функция, которая < 0 на "левых" элементах, = 0 на 
"центральных" элементах и > 0 на правых. Центральные и есть решение задачи. 

Запутался в логике построения ключевого индекса IndexKey32CompImm. Причем запутался в том месте, когда начинает использоваться 
компаратор. Логика построения такова: есть опорная последовательность и именно к ней строится индекс. Для этого, определяется 
функция ключа и строится набор пар {ключ, офсет}. Дальше массив сортируется, первично - по ключу, вторично - по компаратору. 
Компаратор сравнивает два объекта, соответствующих элементам опорной последовательности. Причем сначала сравнение идет по ключу,
а вторично - с помощью компаратора. 

### 20190327 06:53
Так вчера и не "распутался". Есть проблемы с сортировкой по полуключу. Есть проблемы с выборкой по ключу. Итак, вернусь
к конструкции. Есть опорная последовательность элементов. На ней задан ключ (полуключ). Формируется последовательность пар 
ключ-офсет и сортируется по ключу, вторичная сортировка производится по компаратору. Компаратар задан на объектном представлении
элементов опорной последовательности. Поэтому объекты компарации формируются из пары ключ-офсет через чтение из опорной таблицы 
объекта по офсету. 

Теперь о выборке. Есть простая выборка по ключу. Это хорошо работает когда нет компаратора. Предположим, мы можем сформировать
элемент-образец. Тогда мы можем ставить задачу выборки всех элементов из опорной последовательности, "эквивалентых" образцу
по компарации. Но это - "точная" выюборка. Можно попробовать так и сделать. Алгоритм следующий. Мы образец используем в делении
отрезка пополам и, с помощью компаратора, находим ноль, одно или более решение, удовлетворяющее условию сравнения. Этим у меня
занимается некоторая рекурсивная процедура. Процедура есть, но она не сформирована для работы с компаратором. Попробую это 
изменить. 

Сейчас поменял реализацию для нахождения всех записей по заданному ключу. Выборка ускорилась почти в 2 раза! Теперь по субъекту
получаем 1000 запросов за 8 мс. (77 мс. на 10 тыс. запросов). Внимательно посмотрев, я выяснил, что сделал не то. Я вопосльзовался 
массивом пар, расположенным в ОЗУ. Надо применить другое решение. Кстати, хорошо бы иметь понятный и эффективный интерфейс. Для
отдельного инедекса, это взятие всех решений по образцу. Но по образцу чего? Самый "универсальный" вариант - по "образцу" элемента.
Или по образцу объекта (или субъекта), который позволяет что-то. Наверное, на уровне индексного построения, когда у нас есть
ключевая функция и компаратор, правильнее будет подавать псевдоэлемент. Попробую.

Вернул характеристики на 14 мс. за 1000 выборок. Это по субъекту. Теперь буду работать по выборке по объекту. Буду работать 
поэтапно. Сначала только по ключу: сортировка и выборка. Потом подключаем компаратор, опять же: сортировка и выборка. Потом 
выборка по "похожему" значению. 

### 20190329 06:37
Вчера засуетился, много чего сделал, а вот проектом не занимался. Как-то надо исправлять ситуацию, тем более, что просыпаясь, 
я думаю об алгоритмах и логике. "Открытием" последних дней оказалось осознание того, что словарь "ключ-офсет" не является 
универсальным решением для выстраивания динамической части индекса. Видно, что надо использовать что-то вроде SortedTree, но 
такого класса в стандартной библиотеке нет. Возможно, в динамической части индекса лучше оказаться от сортировки и пользоваться 
простым List<T> или LinkedList<T>. Или делать двухуровневую динамику, когда есть напр. SortedList и есть List. Правда SortedList
обладает двумя недостатками. Во-первых - это key-value коллекция. Во-вторых - ключи не могут повторяться, но наверное, это 
следствие первого свойства. 

Вернусь к тому, что надо делать прямо сейчас. Сейчас я работаю над полуключевым индексом. Первое действие, надо существенно 
ускорить сортировку. Идея естественная: сначала пары сортирую по ключу, потом для каждого ключа, идет выделение множества
элементов опорной последовательности и производится сортировка по компаратору. После этого, все пары переписываются из массива
в последовательность. Действую.

18:27

Еще утром сделал двухуровневую сортировку. Построение Build() индекса происходит за 900 мс. (1 млн. триплетов). Теперь 
буду пробовать правильно сделать поиск. 

### 20190330 08:15
Наконец, заработали решения построения индекса на основе ключа и полуключа. В тесте, индекс по субъекту строится на основе 
ключа, индекс по объекту строится на основе полуключа. Для 1 млн. триплетов, оба индекса строятся 4.3 сек., 1000 выборок 
для ключа выполняется 14 мс., для полуключа - 107 мс. В принципе, это не так плохо.

Попробую пропустить тесты на больших размерах данных. 

1 млн. 4.3 сек., 14, 107
10 млн. 47 сек., 27, 151
100 млн. - Ушел в свопинг при загрузке данных (компьютер 8 Гб ОЗУ)

На работе (16 Гб ОЗУ)
1 млн. 5.5 сек., 19, 153
10 млн. 58 сек., 29, 206
100 млн. 755 сек., 19 сек., 279 (ОЗУ использовалась на пределе, странный результат по выборкам по субъекту), диск 3.7 Гб.
100 млн. без загрузки (Refresh) 11 сек., 19, 224

Есть еще режимы, которые надо бы проверить. Первое использование хеш-функции в качестве полуключа. И второе - использование 
функции уровня. Функция уровня задается на элементах опорной последовательности и принимает значения (отрицательное, 0, 
положительное). Выборка формулируется как выборка всех элементов, которые на этой функции равны нулю. Надо попробовать.

Делаю тестовую программу 15. Вернулся к последовательности персон:
```
PType tp_person = new PTypeRecord(
    new NamedType("id", new PType(PTypeEnumeration.integer)),
    new NamedType("name", new PType(PTypeEnumeration.sstring)),
    new NamedType("years", new PType(PTypeEnumeration.real)));
```
Организовал таблицу UniversalSequenceBase, сделал ввод. Миллион записей загружался 300 мс. Теперь добавляю индекс. 
Для начала - на идентификатор. Загрузка стала дольше - 635. Теперь вычислю тестовый запрос. Тестовый запрос правильный,
время выполнения 1000 запросов по идентификатору 12 мс. Испытание на большие размеры
1 млн. load 632, 12
10 млн. load 6.4 сек, 13
100 млн. load 64 сек, 14 
100 млн. без загрузки refresh 900 сек, 14 

Теперь сделаю другие индексы. Более простое решение - исплользование хеш-функции в качестве полуключа. Метод имеет тот 
недостаток, что нарушается монотонность. В частности, это означает, что не видно возможности делать выборки по близким 
именам. Итак, надо написать ключ, далее - посмотрим. 

1 млн. load 980, 19.  total=1003
10 млн. load 10 сек., 20.  total=1076-1100
100 млн. load 102 сек., 22.  total=1300

В общем, все по теории. Но здесь я получаю все решения, хеш-ключ которых, совпадает с хеш-ключом образца. В принципе, 
есть два решения задачи выборки по ключевой функции. Первое решение - фильтровать промежуточный набор и доводить его
до нужного. Второе решение - воспользоваться всем "могуществом" двойной сортировки, заложенной в IndexKey32CompImm.
При этом, мы потеряем что-то. Посмотрю как это будет выглядеть в на этом примере. 

Я проделал все манипуляции "в лоб" - соорудил индекс, там указал функцию (хеш)ключа и компаратор. По реализованным правилам,
если есть компаратор, то шкала не создается. Отсюда и более значительные времена обработки запросов. Теперь 10 млн. персон
обрабатывается: load 40 сек., 1000 выборок по имени 83 мс.

### 20190331 03:49
Что-то не спится... Попробую "наработать" желание поспать.

Вывод из предыдущих построений: надо сохранить обе возможности для получения решения - и фильтрацию после выборки по 
хеш-ключу и бинарный поиск по полному ключу. Теперь надо разобраться с поиском "близких" значений. Сортировку общего плана
я сделал в IndexViewImm. Но она трудозатратна. Это потому, что либо весь массив последовательности долже быть загружен в ОЗУ,
либо будет многократное обращение за элементами, лежащими на диске. 

Я применил IndexViewImm - он основан на ОЗУ и работает быстро. 19 мс. на 1000 выборок. Класс надо бы пределать, но сейчас это 
не так важно. Думаю поработать над этим классом и приведением его в норму. Для этого, для начала, нужно сделать работу с диском.

Кстати, пришла в голову новая идея. Делаю кодирование исходя из статистики. Написал код буквы, потом следующая буква 
определяется следующим кодом. Как-то не так сформулировал. Нам нужно кодировать цепочку символов. Можно использовать частотное 
кодирование, можно - более сложное. Частотное кодирование можно брать из статистики текущего варианта текстов. 

Итак, делаю "чистый" стенд в котром будет загрузка последовательности и вычисление только view-индекса. Итак, "чистая" загрузка
3280 - собственно загрузка. Вычисления - 13 мс. на 1 тыс. запросов. 
1 млн. load 3.3 сек., 1000run 13 мс.

Что-то странным образом изменилось и теперь вычисления выполняются 5 мс. на 1 тыс. запросов. Это на массивах в ОЗУ. Переношу 
вычисления на индексную последовательность. Возьму фрагмент в базовом ключевом индексе.

Вроде получилось! Единичная проверка прошла успешно. Время выполнения 1 тыс. запросов 130 мс. Неплохо!.. Но можно сделать лучше.
Есть такая идея: сделать "редкий" массив значений. Сначала находим интервал в массиве, потом в интервале ищем решение. Интервал,
правда, может объединить несколько отрезков. Как всегда, нас интересует количество обращений к диску при поиске. При бинарном 
поиске, для одного миллиона мы имеем приблизительно 20 обращений. Если сократим интервал до 16-ти, будет 4. Как-то так... Можно 
даже попробовать. 

Проделал некоторый эксперимент. Заменил бинарный поиск в массиве на прямой поиск типа:
```
    var res = elements
        .SkipWhile(ob => comp.Compare(ob, obj) < 0)
        .TakeWhile(ob => comp.Compare(ob, obj) == 0);
```
Поиск работал очень долго - 63 сек. на 1 тыс. запросов. Это более, чем в 10 тыс. раз медленнее, чем с использованием дихотомии.
Попробую добавить дихотомию. Добавил дихотомию. И даже Turple. Теперь на массиве, поиск диапазона выполняется 19-20 мс. на 
тысячу. Системный бинарный поиск работает быстрее, но здесь несколько иная постановка и я не могу им воспользоваться. 
Постановка - найти (минимальный) диапазон в массиве elements такой что первая точка <=0, а следующая за последней точка 
- точно больше нуля. Нет нуля, нет искомой точки... Все же результат неплох. Попробую применить его. 

### 20190401 05:11
День математика, дурака, геолога, Ура!!!

Исправил кое-какие ошибки и... получилось!  
1 млн. load 3.9 сек., 1000run 37 мс.

Это не 13 мс., но и не 130... 

Сейчас подбирал Nfactor. Остановился на 40. Скорость получается несколько хуже - 42-43, но объем использования ОЗУ существенно
меньше. Диапазон высоких скоростей 16-20.

Если делать без загрузки, получается время 150-170 мс. на тыс. Это потому, что Refresh не делает этот массив. 

07:55

Оказывается, я забыл при измерениях сменить режис с отладочного на нормальный. Сменил, результаты 3.4 сек., 38 / 1000

Последний решительный шаг в том, чтобы выполлнять сортировку по частям. Думаю, сделать это "тупо". Сначала делается равномерное
расположение последовательности офсетов. Потом, мы делаем процедуру делания копии части последовательности. Потом делаем
выборку массива объектов и массива офсетов и сортировку по компаратору. Потом начинаем делать сливание массивов с использованием
сравнения. 

19:23

Возвращаюсь к разработке. 

Сделал первую часть: создаю последовательность офсетов, определяю рекурсивный метод 
```
Bld(long start_ind, long number)
```
который сортирует отрезок офсетов по значению объектов. Потом применяю функцию и потом вычисляю разреженный массив. Все
это заработало в режиме, когда используется только оперативная память. Работает с теми же скоростями, что и раньше. 
```
1 млн. load 4.3 сек., 1000run 40 мс.
10 млн. load 47.8 сек., 1000run 61 мс.
20 млн. load 108 сек., 1000run 85 мс.
40 млн. load 500 сек., 1000run 474 мс. - свопинг
```

### 20190402 15:15
Сделал рекурсивную часть Bld. Но пока не работает. Начал отладку, похоже там две ошибки. Буду отлаживать отключив 
прореживание. 

### 20190403 09:51
Исправил ошибки, их оказалось несколько больше двух. Теперь запустил на большой тест, который засерит характеристики на
100 млн. элементов. Использование памяти пока ведет себя пристойно - потихоньку добралось до 7 Гб., теперь уменшилось до 5,
на задачу не досчитала. 
```
1 млн. load 4.3 сек., 1000run 38 мс. (131 без прореживания)
10 млн. load 47 сек., 1000run 60 мс. (171 без прореживания)
10 млн. noload 1.4 сек., 1000run 72 мс.
100 млн. load 1590 сек., 1000run 292 мс.
100 млн. noload 956 мс., 1000run 218 мс.

На 16 Гб ОЗУ:
Поставил объем на 50 млн. единиц
100 млн. load 994 сек., 1000run 189 мс.
100 млн. noload 17 сек., 1000run 195 мс.
200 млн. load 2491 сек., 1000run 250 мс.
200 млн. noload 34 сек., 1000run 243 мс.
400 млн. load 6400 сек., 1000run 349 мс.
400 млн. noload 70 сек., 1000run 311 мс.
```
### 20190405 20:26
Теперь я мысленно нахожусь уже в реализации хранилища триплетов или хранилища записей. Как-то я не определился
в этом вопросе. Хранилище записей проработано неплохо, в частности понятны механизмы добавления, изменения и 
уничтожения. Запись может быть довольно произвольной структурой, Напр. такой:
```
REC = { id: string, fields: { prop: string, val: VALUE }, directs: { prop: string, direct: string } };
VALUE =  empty^ none,
	str^ string,
	langstring^ { lang: string, str: string};
```
Ну или как-то аналогично. К записям можно добавить отметку времени и признак deleted, после этого реализовать 
оговоренную логику слабой динамики. Возникает вопрос с обратными ссылками. 

Другой подход давно обдуман. В нем основной объект последовательности - триплет. Теперь к триплету "приделываем"
логику редактирования: временной маркер и признак уничтоженности. И делаем два (!) индекса spo и op (может ops).
Для качественного хеширования, берем 64-разрядное кодирование. Кодируем строки uri 63-разрядным хешем. А ObjectVariants
кодируем частями: вид - 1 бит, в случае uri, остальная часть - хеш-код. Если значение, то вариант значения. Базовые
варианты: строка, целое, дата, (языковый) текст. Может еще что-то. Spo Хеш-код триплета может выглядеть как: 32 разряда
Субъект, 8 разрядов предикат, 24 разряда объект. 

А если попроще и в рамках 32-х разрядов? Триплеты в проработанном варианте { uri, uri, OVars }. А индексы выстраивать 
неполные. Только по субъекту и только по объекту. По субъекту - просто. По объекту, я прикидывал ключ, состоящий из знака,
как признака Uri/OV. Потом идет целое или хеш целого. По другому варианту, это может быть хеш строки. 

### 20190407 05:52
Я подбираюсь к комплексному решению задач архивного комплекса. Архивного комплекса как распределенной информационной
системы. Можно назвать эту систему "островки" или "архипелаг". Второе - с ассоциацией на архивность. 

Пусть есть множество кассет. Причем как единичных, так и сгруппированных. Кассета, это множество (мультимедиа) документов
и фрагменты базы данных. База данных описывает документы этой группы касет или наборы сущностей, связаных или не связанных
хранящимися в кассетах документах. База данных хранится в формате модифицированного Turtle. Не знаю как насчет пространств
имен, но формат вполне удобен и компактен. Все его возможности мне не нужны, но простая компактизация с использованием 
разделителей ';' и ',' хорошо подходят для моих целей. А цель в том, чтобы изображать целостную запись и чтобы запись не
"расползалась" по тексту и по файлам. Нужен транслятор, но вроде больших проблем нет. 

Онтологию надо применять BONE. Есть некоторые системные расширения: владелец owner, отметка времени mT, isnull или deleted.

А нет ли проблемы в том, что я назначаю атомами триплеты, а транзакции выполняются с записями? Наверное нет, если ...

Итак, рассуждаю. Пусть имеются записи. Во внешнем представлении записи, это набор триплетов, имеющих общие субъекты и имеющие 
общую оболочку. Набор записей составляет один сегмент. Имеются e-сегменты, e это external, и имеются d-сегменты, d - data. 
Множество e-сегментов может быть преобразовано в d-сегмент, но не наоборот. Запись характеризуется идентификатором субъекта,
составляющих ее триплетов. Информационное поле (база данных) состоит из триплетов, составляющих объединяемые записи. Записи
с одинаковым идентификатором конкурируют между собой. "выигравшей" записью считается запись, имеющая более позднюю 
временную отметку. Отсутствие временной отметки трактуется как "очень давно" и любая запись с тем же идентификатором "выигрывает"
у такой записи. В e-сегментах может быть по нескольку экземпляров тождественных записей, в d-сегментах - только один. Отметка
времени - это триплет
```
<subj> b:mT "DateTime" .
```
Еще один служебный триплет - "обнуляет" триплет
```
<subj> b:isnull b:null .
```
Кажется, такая запись избыточна, можно заменить на что-то предикат или убрать (заменить на значение) объект. Но пока будем
действовать указанным образом. Самым сложным в общей семантике записей, является 
```
<subj> owl:sameAs <obj> .
```
И означает она, что все вхождения данного субъекта следует заменить на obj.  

20190408 06:37
Эквивалентность реализовывается с помощью кодирования. Это означает, что используемые uri кодируются, напр. целыми числами,
появляется таблица имен. В таблице имен проставляются одинаковые коды эквивалентным идентификатрам. Такая таблица имен требует
дополнительного построения и не слишком удобна в использовании. Последнее - поскольку ввод осуществляется за два прохода, первый
строит таблицу имен, второй - использует для собственно ввода. Итак, какая требуется дополнительная структура?

Сейчас вспоминал как это реализовано в нынешней версии. Реализовано не очень экономно. Выстраивается table_ri - словарь, имеющий
по входу на КАЖДЫЙ идентификатор, а основным значением словарного определения является список всех эквивалентынх идентификаторов 
данной цепочки. Поскольку ввод идет в два прохода, можно словарь уменьшить до размера только сливаемых идентификторов. Для этого
можно обрабатывать только указания эквивалентности. (Или ввести битовую шкалу?). 

Я проверил, действительно таблица table_ri выполнена неэкономно. А как нужно? Сканируются записи. Если в очередной записи
есть отождествление, то только в этом случае производится коррекция таблицы. Коррекция заключается в том, что проверяется
наличие обоих идентификаторов в таблице переименований. Если идентификатора нет, то вход для него заводится. Если есть, то
используется имеющийся вход. По обоим входам должна быть записана один и тот же список. Причем для других эквивалентных входов
список скорректируется автоматически. Это вообще возможно?  

Я тщательно подумал. Конструкция решения следующая. В словарь попадают только идентификаторы, которые отождествляются. Значение 
в словаре это элемент однонаправленного (двунаправленного?) списка. Ссылка null - конец цепочки. Пусть A и B идентификаторы
отношения 
```
<subj> owl:sameAs <obj> .
```
Мы такое отношение анализируем в контексте уже накопленных данных в словаре
```
Dictionary<string, Node> nodes = ...
```
Пусть A и B отсутствуют в словаре. Тогда создадим два узла и два входа в словарь, а узлу A прямую ссылку на следующий 
установим на узел B. В появляющихся цепочках последний узел (у которого нет ссылки на следующий), является "оригиналом",
т.е. узлом, идентификатор которого предплагается к использованию вместо всех элементов цепочки. Если A присутствует в словаре,
а B отсутствует. Тогда к последнему элементу цепочки A "приделываем" узел, образованный от элемента B. Если наоборот, B имеется,
а A отсутствует. Тогда цепочку B удлиняем с головы. Если есть оба элемента и есть их цепочки, то к последнему элементу цепочки
A прикрепляем цепочку B. Вот здесь и кроется "засада". Дело в том, что от элемента B у нас нет возможности найти первый элемент 
его цепочки. Выход понятен - сделать двунаправленный список. Ну нужен ли нам первый элемент цепочки? Мы прикрепляем цепочку
A к любому узлу B и этого достаточно для того, чтобы выйти к последнему. Получается дерево с корнем в последнем узле. Если надо
распространить что-то на все узлы цепочки, то нужны двунаправленные связи, а добраться до корня, можно и по однонаправленным. 

### 20190409 08:30
С утра думал о том, что надо бы активировать конференционную и публикационную активность. Придумал то, что могу подать доклад
на Ершовскую конференцию. Придумал название, попробую его воспроизвести. "Технологическая цепочка для локального хранилища
документов и данных". Как-то так... 

Написал несколько больше одной страницы, завтра продолжу. 

Главная неразрешимость моих размышлений - это "языковый барьер", т.е. как эффективно представлять langString. Для самих 
значений, это сделать несложно, но экономномная хеш-функция не получается. Более того, непоянно как организовывать стравнение
языковых строк. "en" и "en-US" это одно пространство? Или та часть английского алфавита, которая совпадает с французским
может быть использована для поиска? А может языковый тег вообще непричем в задаче поиска? Почему не искать по char?

### 20190411 20:08
По "языковому барьеру" идея такова: мы будем использовать англо-русские символы. Т.е. стандартные английские и добавленные
русские. Никакого языкового спецификатора на стадии определения похожести текста на образец. Как-то так...

### 20190412 05:42
День космонавтики! Какие героические годы были 50-е и 60-е. И почему сейчас Россия не может развиваться аналогично?..

Честно говоря, я что-то застрял на отвлечении на Поляр. В принципе, я хотел сделать индексы, я их сделал. Последний индекс, 
которым я занимался - IndexViewImm. Все вроде неплохо, но есть некоторая проблема: поиск в режиме студии выполняется за 39 мс.
на 1 тыс запросов, а в консоли - 97 мс. на 1 тыс. Это в 2.5 раза! Непонятно...

Сейчас провел несколько экспериментов. Так и не разобрался... Ну да ладно, это не главное.

Теперь вспоминаю, что я хотел сделать хранилище триплетов, более того, что-то уже делал. Попробую снова, но теперь под 16-м
проектом. А начало кода возьму из 14-го. 

### 20190413 09:49
Я готовлюсь к тому, чтобы сделать и испытать хранилище триплетов. И мне все не дает покоя вопрос с реализацией обратного
отношения. Я вот подумал, что ыполне может быть два и более родственных индекса. Например, наряду с индексом по значению,
может быть индекс по коду uri. И этот индекс может быть довольно эффективным. Ранее, я всегда предполагал, что число элементов
в простом индексе совпадает с числом записей в опорной таблице. Но откуда это следует, и где это используется? Потом выяснилось,
что для слабой динамики это не так, что там индекс достраивается каким-то динамическим сооружением. Итак, вопрос: как сделать 
индекс, с числом элементов, не совпадающим с числом опорных элементов. Вроде все просто: если ключевая функция выдает null, то
не делать индексную точку. Но можно и по-другому: при индексировании передавать массив ключей для данной записи. Технически, 
это будет векторный индекс или как его можно еще назвать "словарный индекс". Попробую пойти этим путем, тем более, что векторный
индекс всяк нужен в комплекте. 

Для тестирования, добавлю ссылку parent в персональную запись и тест будет выдавать детей персонажа. 

Итак, тестирование прошло. Временные характеристики хорошие. для 500 тыс. персон прямые запросы по клиючу выполнялись 18 мс. на
1000, обратные 13 мс. / 1000

- объем, загрузка, прямые, обратные
- 500 тыс., 1424, 18, 13
- 5 млн., 14.5 сек., 18, 13
- 50 млн., 161 сек., 43 сек., 13 сек.

### 20190414 07:41
Идея делать индексы не под абстрактную потребность, а под конкретную, выглядит интересной. Обратный объектный индекс уже 
получился эффективным. Еще эфективнее будет сделать отдельные индексы под типизацию и под обратные отношения. Самое забавное, 
что если не делать пересечений в индексируемых записях, то объема индексных таблиц это не увеличивает. Некоторую настороженность 
подход вызывает из-за кодирования. Но может, все не так плохо. Мы сначала делаем ввод триплетов. При этом, выполняется 
кодирование. После начального ввода, при должной технологии, уже некоторые uri определятся, так что можно их закладывать в 
функции. Можно и по-другому - делать ключевую функцию на строковом представлении триплета. Но это возможно только если функция
используется только перед сортировкой. 

Я под утро продумал устройство хранилища триплетов и у меня теперь "чешутся руки" это попробовать. Осталось не так много: сделать
хорошую таблицу имен и слабую динамику. Подумаю над таблицей имен. Проще всего таблицу имен каждый раз делать заново. Вот есть 
хранилище триплетов. Там сначала ничего нет. Кроме пустой таблицы имен и пустой последовательности. Технически, надо бы иметь
возможность внести в таблицу имен несколько констант. А потом вносим триплеты. Потом определяем функции ключей для индексных
построений. Потом делаем индексы, протом запускаем слабую динамику. Все это я уже проделывал, теперь надо повторить. Причем
повторить максимально просто, прозрачно, эффективно. 

Попробую сделать хранилище путем втягивания в работающее решение других функциональностей. 

Проблема, надеюсь маленькая, возникла при реализации таблицы имен. Для таблицы имен номер элемента в последовательности и есть
код элементы. Но не хранить же его, когда он зафиксирован в таблице офсетов... Или хранить? Попробую порассуждать. Минимальный 
вариант индексных построений следующий: table - последоватльность строк, str_offsets - последовательность офсетов предыдущей 
таблицы, name_index - индексное построение из ключей и офсетов, отсортированных по ключам. В качестве ключей используется 
хеш-код строки. Когда есть строка-образец, проводится поиск множества совпадающих с хеш-кодами пар. Здесь есть пара проблем.
Одна проблема в том, что по значению офсета еще надо проверяь то, что элемент совпадает с искомой строки. Вторая та, что по 
офсету строки еще надо поискать код, это что, надо снова запускать бинарный поиск? Отказываться от последовательности офсетов
не выгодно, потому что по коду легко находить строку. Похоже, естественным решением является сделать опорную последовательность
в виде последовательности пар {код, строка}. Буду делать. 

Что-то сделал и засомневался. Надо отбросить сомнения и действовать...

### 20190415 05:44
Начал доделывать таблицу имен и двигаться в сторону комплексного решения по хранилищу триплетов. Теперь мне понадобится тест 
"фототека". Написал генерацию персон, пока я не загружаю данные, только кодирую триплеты. Скорость неплохая: для 4 млн. персон
триплеты кодируются 9.5 сек. Из них собственно кодирование выполняется 7 сек. Теперь проверю что получилось. 

Что-то я изменил. Теперь 40 млн. персон загружаются (кодируются) 121 сек и строится индекс 152 сек. Проблема в том, как
корректно организовать работу по подключению к данным, по загрузке, по построению. Можно Build выполянть периодически,
по переполнению лимита для словаря, в конце работы, в начале работы. Причем можно посмотреть на полноту вычисленного 
индекса и тогда принимать решение о построении индексной последовательности или словаря. Индексная последовательность 
может быть также разбита на большую и малую. Это замедлит доступ, но ускорит старт.

Провел эксперимент с тестом Фототека на размере 4 млн. (100 млн. триплетов). Так вот, загрузка производилась 112+110 сек.

Я хотел подумать насчет переходных процессов в идексах, снабженных слабой динамикой. Дело в том, что изменения в индексах 
какое-то время накапливаются в динамических структурах. Предположим, выключилось питание. После включения, мы имеем 
рассогласование, поскольку не восстанавливали динамическую составляющую. Есть три способа решения задачи: восстанавливать 
динамическую структуру, обнулять индекс и строить по-новому, делать второе в фоновом режиме. Похоже, что для того, чтобы 
корректно работать с динасическими индексами, в индекс надо добавить два поля: номер следующей записи опорной 
последовательности и офсет следующей записи там же. По этому номеру можно произвести стравнение с количеством элементов в
опорной последовательности и создать динамическую структуру. Либо сформировать новый вариант индекса. 

Эти соображения коррелируют с некоторым общим поведением индексов. Индексы порождаются, индексы присоединяются, строятся, 
инициируются, элементы в опорную таблицу помещаются. Пока все это богатство не описано, буду продолжать строить экспериментальное
хранилище. 

### 20190416 08:03
Ночью и частично ранним утром запистил тест Фототека. Вроде работает, хотя надо бы убедиться в том, что делается именно
то, что хотелось. 

Протестирую полученное решение
```
40 тыс. 238
400 тыс. 274
2 млн. загр. 700 сек., 316 / 1000 !!!
4 млн. загр. 490 сек., 347 сек. / 1000
```
Расчеты показывают, что в решении есть дефекты. В частности, f6.bin остался незаполненным. Кроме того, без загрузки на 2
млн. 1000 запросов выполняются 746 сек! Видимо, это свидетельствует о том, что разогрев работает плохо. 

Действительно, разогрев не работал. Включил, получилось нормально. Для фактора 400 тыс., разогрев выполняется 11 сек., 
выборки 288. Тогда как в полном варианте, загрузка 19 сек., выборка 284. Что-то слабовато работает разогрев...

Появилась идея: разбить разогрев на 2 этапа. 1-й этап обязательный, там должны выполняться обновление массивов, использование
которых критично для достижения высоких значений производительности. 2-й этап необязательный или выполняемый в фоновом 
режиме. Это разогрев (очень) больших файлов. Причем таких, которые нужны для "однократного" доступа в рамках запроса. 

### 20190417 09:42
Главное - двигаться! Поставил задачу сделать простое хранилище триплетов, надо выполнять. Собственно 2 индекса я уже сделал:
прямой и обратный, теперь надо сделать индекс на имена. Я уже такой делал, но все же надо еще раз подумать. И сделать! Посмотрю 
код.

В хранилище есть последовательность объектов типа tp_triple, причем триплет состоит из полей субъекта, предиката и объекта. 
Субъект и предикат - простые строки uri, объект - (объектный) вариант iri, строки, целого, даты и языковой строки. Как 
использовать триплеты, это мы еще подумаем. Но в хранилище есть еще три индекса. Еще все uri в триплетах кодируются с помощью
таблицы имен. Еще есть три индекса. Один дает возможность выбирать объекты триплетов по полю субъекта, второй - по значению
объектного объекта, третий индекс соответствует некоторым строкам в "строковом" объекте. Реально, я собираюсь это поле
использовать для поиска по name, причем поиска по совпадению начальной части имени. 

Вообще, построение индекса под схему и под данные, может оказаться "новым словом" в проблематике баз данных. Итак, делаю 
третий индекс и проверяю его. 

Я подумал, что можно довольно сильно искажать локальный алфавит, применяемый для формирования хеш-ключа. Например, мы можем
взять русские (32 буквы) и латинские (24) буквы и получить алфавит, кодируемый 6 символами. 5 букв будет укладываться в
одинарное целое и еще 2 бита остается. При этом, возможна разная стратегия реакции на отсутствующий в "алфавите" символ. Можно
его просто пропускать, а можно вместо него ставить какой-то символ, напр. '*'. Можно еще проредить буковки, напр. вместо 
латинских, использовать только какую-то латинскую букву, можно выбросить (скорее - заменить) гласные или редко применяемые буквы
и т.д. и т.п. Все это возможно тогда, когда a = b влечет code(a) = code(b), а значит, мы не пропустим равенства если равны 
кодирования. Еще надо иметь неравенство треугольника. Пусть студенты подумают. 

Теперь надо вернуться к каноническому индексу, которым у нас является IndexKey32CompImm. Сейчас он недоделан, но кажется,
его вполне можно доделать. Как устроен (этот) индекс? В целом, это последовательность пар: {ключ, офсет}. Каждая пара 
порождена от элемента, начинающегося с указанного офсета. Важное новшество: от одного элемента может появиться несколько
пар. У этих пар общий офсет, но разные ключи. Итак, индекс первично определяется ключевой функцией, которая порождает поток
(ноль, один, два, много...) ключей. Офсет берется из вычисления. Пары сортируются по ключам, при равенстве ключей, для 
сортировки используется компаратор. Компаратор может отсутствовать (быть нулевым), тогда есть задача сортировки упрощается
и задача выборки формулируется как выборка по ключу. Теперь пусть компаратор ненулевой. Тогда множество пар, распавшееся 
на непересекающиеся подмножества с одинаковым ключевым значением, дополнительно сортируются по компаратору.

При наличии компаратора, какая задача решается при выборке данных? В этом месте похоже не удастся обойтись без 
(поискового) экземпляра элемента опорной последовательности. Вообще-то это довольно странно, потому что такой элемент, как
правило, даже в принципе не мог бы существовать. А так, при наличии "поискового экземпляра", требуется найти все элементы 
опорной последовательности, у которых и ключ совпадает с ключем образца и компаратор дает ноль. В некоторых случаях, выборки 
подчиняются другому правилу - "правилу уровня". Это когда задается на элементах функция уровня. Это происходит, когда ищутся
значения "близкие" какому-то образцу. Например для лексикографического упорядочивания, поиск "близкого" значения может 
реализовываться через фукцию уровня 
```
public int LevelFunc(obj, string sample) 
{ 
	string s = ....; // значение строки, взятое из объекта
	int cmp = string.Compare(s, 0, sample, 0, sample.Length, true);
	return cmp;
}
```
Поиск должен выдавать все элементы опорной последовательности, на которых LevelFunc выдает ноль. Согласованность этой 
функции с функцией ключа и компаратором должна определяться разработчиком. Это еще в дополнение к тому, что когда определяются
"близкие" значения, то нужна согласованность еще и с ключевой функцией. 

### 20190418 08:03
Попробую заложить описанные возможности в упомянутый класс. Только переименую его на полное название: IndexKey32CompImmutable.

### 20190420 06:28
Сделал новый класс, но изрядно помучался с отладкой.

Итак, в классе IndexKey32Immutable есть: конструктор класса, Clear, Count, Build, Refresh. Суть их в том, чтобы построить 
или активировать индекс. Индекс задается двумя определениями. Во-первых, это функция KeysFunc, преобразующая объектное
представление элементов опорной последовательности, во-вторых, возможно задание компаратора, сравнивающего эти элементы. 
Логика индексного построения в том, что оно 1) выделяет из множества элементов какие-то; 2) формирует систему поиска элементов, 
попавших в выделение. Элементы выделяются тем, что ключевая функция имеет множественный результат. Если формируется пустое
множество, то по данному индексу элемент недоступен. Если непустое, то элемент доступен через каждое значение ключа, формируемое
функцией. Что значит, что доступен через значение ключа? Пары {ключ, элемент} выстраиваются в какую-то структуру, по значениям
ключа, напр. сортируются. Напомню, что в данном индексе ключ - 32-разрядное целое. 

Какую задачу решают индексы? Задачу эффективного выхода на подмножества элементов через задание каких-то значений. 
Итак, основной способ упорядочивания доступа к элементам через индекс, выстраивание ключей. В данном случае, 32-разрядных целых.
Ключи можно отсортировать и можно обеспечить выборку по конкретному ключу. Конкреный ключ получается применением ключевой
функции к элементам опорнорй последовательности. Независимая генерация поискового ключа лежит на ответственности разработчика.

Типовые способы применения IndexKey32CompImmutable. Первый - уникальная индентификация целочисленным идентификатором. Выборка по 
ключу решает проблему. Выборка по ключу выполеняется методом:
```
	public IEnumerable<object> GetAllByKey(int key);
```
Второй - строковая идентификация. Тогда в ключевой функции применяем хеш-функцию и при выборке применяем
ее же. 

Возникла проблема. Что-то "утвержденный" индекс не демонстрирует нужных характеристик. Пытаюсь найти проблему. 

Старый вариант: Загрузка 856, запросы 14 / 1000
Новый вариант: загрузка 640, запросы 72

Это что-то грубое. Посмотрю код. Нашел, исправил, работает хорошо.  

Новый вариант: загрузка 632, запросы 12-13
10 млн. 6.5 сек., 14
100 млн. 72 сек., 20 сек.
100 млн. без загрузки Refresh 826 сек., 14 сек. (из холодного состояния, Refresh выполянется 30 сек.)

Следующее испытание строковая идентификация. Есть строки, требуется сделать индекс, который бы эффективно работал бы
по ключу. Есть два способа для решения: без привлечения вторичной сортировки и с привлечением. Попробую первый вариант. 
```
    var os = str_index.GetAllByKey(Hashfunctions.HashRot13("" + k))
        .Where(ob => (string)((object[])ob)[1] == "" + k); 
```
Такой вариант работает очень хорошо. Но надо иметь ввиду, что наложений при таких характеристиках задачи чрезвычайно 
мало. Мои измерения показали 0.1-0.3%. Скорости получились:
1 млн. 650, 20


Теперь попробую другой вариант.

### 20190421 06:30
Другой вариант не получился, потому что я не согласовал сортировку по значению хеш-функции и детальную сортировку. Такое 
согласование можно сделать используя  int First4chars(string s). Правда там есть нюансы, связанные с сортировкой русского
языка, но надо эти нюансы преодолевать.

1 млн. 3.9 сек., 61
10 млн. 38 сек., 100
50 млн. 223 сек., 98

Результаты выглядят хорошими. Можно возвращаться к проектированию хранилища триплетов.

Итак, надо наметить план. Сейчас пройдусь по коду 16-й программы, сделаю изменения в соотвествии с (рекомендациями) Main17.
Надо довести все это до более или менее рабочего варианта. Пока без слабой динамики.

Сразу буду отмечать что надо будет сделать позже. 

1) Таблицу имен надо полностью "втянуть" в хранилище.
2) Объединить в интерфейс общие действия с индексами - построение, обновление и т.д.
3) Сделатиь слабую динамику

Пол дня искал ошибку. Нашел, исправил, появилась еще одна. Еще пол дня искал... Теперь могу провести некоторый контрольный 
расчет. Итак, загрузка, выборка по субъекту, выборка по имени

40 тыс. 3.8 сек., 249, 287
400 тыс. 39 сек., 297, 2625 (надо поработать!)
4 млн. 612 сек., 196 сек., 27 сек.
4 млн. без загрузки 52 сек., 329, 28 сек., объем файлов базы данных 4.64 Гб.

Пора позаниматься ответственными делами, отключаюсь...

### 20190422 06:20
Не все меня устраивает из проделанного. Для ориентировки, решил проделать эксперименты с View-индексом IndexViewImm.
По использованию диска, он экономный и как-то мне удалось решить основные проблемы, связанные с ним. Запустил, получил:
1 млн. 4.5 сек, 39
10 млн. 46 сек., 42
20 млн. 98 сек., 44
40 млн. 210 сек., 46
60 млн. 330 сек., 51
80 млн. 473 сек., 134. Без загрузки 11 сек., 47
100 млн. 623 сек., 47
150 млн. 1072 сек., 108. Без загрузки 19.5 сек., 47

Продолжение таблицы сделаю на рабочем компьютере (16 Гб. ОЗУ) с параметром 50 млн.
200 млн. 1763 сек., 381, без: 41 сек., 64
500 млн. 5674 сек., 5800, без: 211 сек., 4226
10 млн. 50 сек., 56, без: 1.5 сек., 59

А теперь выполню этот же способ с целочисленной колонкой id
1 млн., 1.5 сек., 46
10 млн., 16 сек., 44
100 млн., 207 сек., 47 (2.31 Гб)

Стандартный способ получается
1 млн., 0.7 сек., 16
10 млн., 6.7 сек., 16
100 млн., 68 сек., 16 (2.71 Гб)
200 млн., 136 сек., 16. Без: 1.5 сек., 16

Я до сих пор не сделал поиска похожего значения. Как это лучще сделать?

### 20190423 09:33
Попробую сделать подходящий компаратор. 

### 20190424 25:28
Ура, справился! И практически без новых накладных расходов. Всего лишь сделал возможность запускать IndexViewImm 
с компаратором. Соответственно, научился делать компаратор такой, что он берет длину сравнения их длины второй строки.
Что теперь делать?

### 20190425 08:36
Попробую описать новый вариант IndexViewImm. Это индекс, который "работает" на призвольной последовательности, не элементах 
которой задан дефолтный компаратор. Дефолтный, потому что будет еще и не дефолтный. Компаратор упорядочивает элементы 
последовательности. Соответственно, будучи построенным, индекс позволяет делать запрос относительно образца: 
```
public IEnumerable<object> SearchAll(object sample);
```
где задается образец, результатом будет набор всех элементов последовательности, которые "совпадают" по компаратору с образцом. 
Образец задается в объектном представлении и важно, чтобы на нем компаратор "не ломался". Другой вариант запроса:
```
public IEnumerable<object> SearchAll(object sample, Comparer<object> comp_current);
```
В нем динамически задается компаратор относительно которого ищется "совпадение". Компаратор c должен быть согласован с 
дефолтным компаратором. Это означает, что если 
```
comp_current.Compare(x, y) != 0, то comp_default.Compare(x, y) == comp_current.Compare(x, y)
```
По существу, это означает, что упорядочение, вычисленное на последовательности, упорядочивает последоваетльность и по новому
компаратору. В качестве примера такого "текущего компаратора", можно задать на последовательности лексикографически
упорядоченных строк компаратор:
```
Comparer<object> comp_like = Comparer<object>.Create(new Comparison<object>((object x, object y) =>
{
    int len = (string)y.Length;
    return string.Compare((string)x, 0, (string)y, 0, len);
}));
```
Такой компаратор будет считать совпадающими не только строки, которые полностью совпадают, но и те, которые совпадают в
в количестве символов строки второго аргумента. 

Некоторой реализационной особенностью индекса является то, что для больших последовательностей требуются временные файлы, 
поэтому в конструктуре надо указать имя диретории для временных файлов. Вообще, индекс, как обычно, строится методом Build()
и "оживляется" методом Refresh(). Метод Build() требователен к использованию оперативной памяти. Объем памяти, который 
разрешается использовать конструктору, задается параметром long volume_of_offset_array, этот объем задается в числе длинных 
целых (8 байтов каждое).

Есть существенная оптимизация данного индекса - динамическое хранение "прореженного" массива отсортированных элементов.
Это означает, что 1/40 часть последовательности представлена в массиве ОЗУ своим объектным представлением. Для очень больших 
последовательностей, реализованный подход "загонит" систему в свопинг. 

Как-то так...

Проверку работы выполню на 10 млн. элементов?
загрузка 46 сек., выполнение 1000 запросов 43 мс. 
без загрузки 1.6 сек., выполнение 1000 запросов 53 мс.


### 20190427 17:54
Переехали на Семинский перевал. Сейчас смотрю что есть, что можно делать, какие условия для работы. 
Пропустил тот самый тест. Во-первых, я не знаю почему здесь в студии для Windows-10 рабочая директория 
определяется правильно, как в документации, тогда как в семерке, рабочая директория совпадает с кодом. 

Во-вторых, исполнение происходит ГОРАЗДО медленнее, чем на десктопе. Стандартный тест на 1 млн. элементов
дает время загрузки 18 сек., время исполнения 1000 запросов - 313 мс. А 10 млн?
10 млн. 216 сек., 403 мс.

Есть правда подозрение, что компьютер занимается обновлением. Потом еще попробую пропустить.

Похоже, действительно, фактор занятости компьютера имеет место быть. Сейчас прошло довольно много
времени и пропуск показывает другие цифры:
1 млн.: 8 сек., 236 мс.
Раза в 2 по времени загрузки и раз в 5-6 по времени вычисления. Уже не шокирует...
Снова плохо! 16 сек. и 440 мс. Даже и не знаю как это понимать. Может включается и выключается режим
экономии потребления. Что-то такое уже было в совершенно другой ситуации. Причем ровно в 2 раза...

И сейчас ровно в 2 раза: 16 сек., 550 мс. Подозрительно...

Однако, пора двигаться дальше. Это "дальше" - прототип хранилища триплетов. Попробую свести воедино 
то, что попробовал. План такой:

1. Создаю проект TripleStore
2. Делаю начало класса TripleStoreExperimental
3. Делаю простейший TTL-парсер. 
4. Делаю тестовые данные в формате ttl.
5. Делаю ввод тестовых данных

Дальше план додумаю. Можно уже начать. 

### 20190428 11:49
Идет акклиматизация. Раньше это проходило проще...

Что-то я задумался о методах, которые надо сделать в хранилище и о названиях методов. Попробую "подумать"
"вслух". Основой интерфейса должны стать методы получения множества треплетов по какому-то условию. Условия 
следующие: 
- задан субъект, или субъект и предикат, или субъект, предикат и объект
- задана "цель" (target), или цель и предикат
- задано данное (data), или данное и предикат
- задано похожее данное.

Комментарии к этим вариантам. Третий подвариант перового варианта имеет тонкости. Во-первых, важны не 
значения триплетов, а пустое или непустое множество вариантов. Во-вторых, непустое множество вариантов
должно содержать ровно один элемент. Это по правилам RDF о том, что все триплеты должны различаться. 
Подозреваю, что это утверждение следует из логики предикатов. Для меня важно, что свойство единственности
проверяется или нет? Лучше бы не проверять. Иначе добавление предиката станет более "тяжеловестым". 

Второй комментарий касается работы с данными. Заданность данного в реальной фактографической системе пока (!)
допустимо только в задании имен. Кстати, это является специфической ситуацией и хорошо бы иметь средстве 
ее определения. Если говорить о практике, то заданное имя надо искать (только) в предикатах name и alias.
причем первый предикат в реальных онтологических сборках имеет сколько-то синонимов. Кроме того, имя может 
быть разделено на составные части (напр. ФИО), что дополнительно усложняет ситуацию. 

Но даже в простой ситуации нашей базовой онтологии, есть "подводные камни". В частности, предикат name,
это предикат именованной сущности, а предикат alias - это отношение, ведущее к именованной сущности. 
Наверное, надо исходить из того, что это вопросы системы более высокого уровня. 

Похожий вопрос возникает когда мы выделяем какой-то вариант или какие-то ворианты для того, чтобы их 
специально индексировать. Пусть имеется индекс, который позволяет по заданному s выдавать множество 
триплетов. Это множество можно разбить на треплеты с конкретным значением предиката p0 и остальные. Допустим,
мы сделали 2 индекса на s\p и s,p. Теперь мы решаем задачу Get_s(s). Она решается в 2 этапа. Поиском в
первом индексе и поиске во втором. Если рашется задача Get_sp(s, p), то сначала определяется p=p0? и в 
зависимости от ответа, поиск организуется в соответствующем индексе. Процедура может быть обобщена на
произвольное число специальных случаев. 

Подобный "трюк" я задумал с предикатом type. В типизованной системе он встречается часто и надо это учитывать.

Однако, все эти премудрости пока не актуальны. Актуальны Get_s(s), Get_sp(s, p), Get_t(t), Get_tp(t, p), 
Like(d). Последний "работает" на специально определенном множестве триплетов. Второй и четверый варианты
делаются фильтрацией первого и третьего. Вернусь к коду класса и тестирующей программы.

Что-то сделал, но что-то "с наскоку" сделать не получается. В частности, не получается быстро воспроизвести 
слабую динамику. Надо вспоминать, надо соображать... Так что сделаю пока без слабой динамики. Пока можно 
объединить действия Clear(), Build(), Refresh(). А потом, как нибудь, подумаю. Да, еще нюанс: надо в опорной
таблице вести список индексов. Думаю, можно сделать такое добавление непосредственно в UniversalSequenceBase.

Все, вроде нашел ошибку. Как ее исправить, подумаю завтра. А сегодня надо отдохнуть. 

### 20190429 06:15
Ошибка оказалась в разреженном массиве. Я заблокировал его использование и особый случай заработал. Сейчас
посмотрю код.

Все! Пока сдался! Я вижу ошибку, причем создал ее на маленьких данных, но в исправлении шел по неправильному 
пути. Надо начинать сначала, но как-нибудь потом. 

В тесте Фототека, ошибка выскакивает на данных: число персон 400, поиск персоны по имени "p24". 

Порассуждаю. Вот у меня разреженный массив значений. Вот значение. Беру самый левый элемент массива. Он,
по построению совпадает с самым левым элементом последовательности. Делаю сравнение с образцом. Если 
сравнение > 0, то надо выдавать пустую последовательность результатов. Если значение =0, надо сканировать 
элементы от нулевого до того, на котором станет >0. Исключительно. А если сравнение дает <0, то это базовый 
вариант и надо рекурсивно произвести поиск точки начального сканирования. Точка начального сканирования 
является индексом, значение сравнения элемента из массива строго <0, а на следующем элементе >=0.

Похоже, эту задачу можно свести к поиску в массиве... Кажется нет, там нет гарантии, что будет найден первый
элемент, удовлетворяющий условию. С другой стороны, можно получить какое-то решение и немного "подвигаться"
влево. Это все в ОЗУ, должно выполняться быстро. Можно попробовать...

### 20190430 06:14
Помучился изрядно, но первично закончил исправлять ошибку. Там есть над чем еще работать, но все уже терпимо.

### 20190501 03:03
Да здравствует 1-е мая, день международной солидарности трудящихся! Я ведь трудящийся, правда?

Вчера по элементам заработало все, кроме слабой динамики. А сегодня надо бы формировать основу целостного 
решения. Посмотрю на класс TripleStoreInt32, который получился. 

Посмотрел, "почистил перышки" в коде, вполне удовлетворился. На самом деле, это решение - самое начало.
Далее, нужно "присобачить" две обертки: обертку слабой динамики и обертку фог-данных. Вкратце опишу свое
понимание этого вопроса. Обертка слабой динамики должна позволять добавлять и убавлять триплеты. При этом, 
корректируя индексы. 

### 20190502 08:32
Я вчера придумал важную инновацию. Вопрос о том, куда поместить признак уничтоженности элемента. Решил, что
самое удобное место - в тег варианта ObjectVariants. И теперь вариантный тип будет выглядеть:
```
    PType tp_ov = new PTypeUnion(
        new NamedType("deleted", new PType(PTypeEnumeration.none)),
        new NamedType("iri", new PType(PTypeEnumeration.integer)),
        new NamedType("str", new PType(PTypeEnumeration.sstring)),
        new NamedType("int", new PType(PTypeEnumeration.sstring)),
        new NamedType("date", new PType(PTypeEnumeration.sstring)),
        new NamedType("langstr", new PTypeRecord(
            new NamedType("lang", new PType(PTypeEnumeration.sstring)),
            new NamedType("str", new PType(PTypeEnumeration.sstring)))));
```
У-упс... Здесь я и 
прокололся! Просто сделать отметку в триплете об уничтженности не получится, увы... Дело в том, что значение 
должно считываться полностью, это нужно хотя бы для сканирования. Так что указатель варианта должнен 
присутствовать в неизменном виде. Так что придется признак поставить в другое место, думаю, между полями 
предиката и объекта. Как-то так:
```
    PType tp_triple = new PTypeRecord(
        new NamedType("subj", new PType(PTypeEnumeration.integer)),
        new NamedType("pred", new PType(PTypeEnumeration.integer)),
        new NamedType("deleted", new PType(PTypeEnumeration.boolean)),
        new NamedType("obj", tp_ov));
```
Это неудобно, поскольку меняет нумерацию полей в объекте триплета, но лучше сейчас, чем потом. Помещать
этот признак нужно в зону, адрес которой может быть легко вычислен по офсету записи. В принципе, 
это необязательно, но кажестся важным для оптимизаций. Другой вариант - поместить в начало. Тогда нумерация 
также изменится. В общем, самое время подумать...

Подумал и решил вернуться к старой схеме структуризации последовательности триплетов, более того, 
просто последовательности типизованных объектов. Опорная последовательность является последовательностью
записей из двух полей: булевского deleted и структурного element. В данном случае, не потребуется "курочить"
тип триплета. На этой опорной последовательности реализуется логика слабой динамики. 

Логика слабой динамики следующая:
1. В хранилище хранится множество Q-объектов. Q-объект (qualified object) - это пара состаящая из 
структуного объекта какого типа и признака уничтоженности. Никакого смысла в уничтоженных объектах искать не надо,
но это должны быть корректные поляровские объекты. Хранилище может очищаться и может заполняться из потока объектов.
Хранилище может сканироваться. 
2. 

### 20190503 06:14
Надо посмотреть предыдущие наработки. Меня заинтересовало как я оформлял опорную последовательность.
Посмотрел, ничего особенного. Буду двигаться дальше. Итак, вернусь к основам. Надо изложить и реализовать
логику построения некоторых универсальных последовательностей. Назовем их опорными (bearing). 

Опорная последовательность, это последовательность типизованных элементов для которой обеспечивается некоторая
специальная функциональность. На опорную последовательность можно "навесить" произвольное количество индексов 
(см. далее). Эти индексы, с одной стороны, расширяют фукциональность последовательности, с другой стороны, 
"отрабатывают" редактирующие действия с последовательностью так, чтобы выполнялись некоторые инварианты, т.е.
чтобы индексы не потеряли логики своего построения. 

Тут что важно? Сначала опорная последовательнсть декларируется, декларируются также ее индексы, потом чистится,
загружается, потом начинается слабая динамика, потом идет возврат к чистке/загрузке/работе. Есть некоторое 
внешнее представление базы данных и от него всегда можно загрузить опорную последовательность и вычислить индексы.
Попробую как-то это превратить в библиотечные решения. Вернусь к GetStarted. Начну подпроект Program18. В нем я
заведу опорную последовательность. Тип элементов - стандартный (id, name, age). В общем, пройдусь по стандартному
пути с двумя (разными) индексами и выборке как по ключевому индексу так и по лексикографической похожести.

Опорная последовательность первично сделана и заработала. Пора "присобачить" индексы. Я хочу, чтобы конструирование
всей базы данных было бы единым процессом. Поэтому индексы следует задавать прямо в конструкторе. Попробую. 

### 20190504 06:29
Вроде все движется, но есть неочевидности и вопросы о том, как что-то сделать правильнее. Сейчас "завис" между 
последовательностью и опорной последовательностью. В принципе, индексные построения будут работать с любым из 
представлений. Самое смешное, что и уничтожение можно делать без "опоры". Рассмотрим простую ситуацию: делаем 
key-value хранилище. Используем для этого простую (UniversalSequenceBase) последовательность. К этой 
последовательности обычными средствами "приделываем" ключевой индекс. Получилось! Теперь добавляем элемент с
новым ключем - нет проблем! Потом добавляем элемент с существующим ключом. Это делается также естественным
образом: добавляем элемент в последовательность, корректируем ключево индекс. Эта коррекция индекса (вход в
Dictionary<Tkey, long_offset>) "заслоняет" старое значение, сопоставленное с ключом. Таким образом, база данных
снова работает! Если договориться о том, какое значение считать нулевым, то и уничтожать элементы получается
если под уничтоженным значением понимать то, которое выдает null на выборку по ключу. 

А чего не будет? Трудно реализовать сканирование элементов последовательности, хотя и можно. Просто надо 
сканировать и каждый элемент проверять на то, тот ли это элемент, соответствующий данному ключу. А еще возникают
проблемы с повторным построением индексов. Собственно задача сводится к сканированию, а сканирование мы уже
обсуждали. Для более сложных индексных построений также могут возникать трудности. 

Итак, вопрос: надо ли сразу ориентироваться только на опорную последовательность или можно обобщить это решение?

Сходил к стелле, позавтракал, принял лекарства, подумал - ответ: надо обобщить решение. Для этого, описать
интерфайс IUniversalSequence и к нему привязать действия индексов. Пробую...

### 20190505 06:08
Вчера так и не решил как нужно сформировать "правильную" последовательность. Ночью об этом думал, пришел к выводу,
что мои проблемы в том, что я из базового класса UniversalSequenceBase пытаюсь сделать больше, чем он из себя
должен представлять. В создании индексируемой последовательности, надо опираться на специальный, опорный (bearing) 
класс. В этом классе как-то спрятаны (упакованы, обернуты) элементы последовательности, а также есть поля и признаки,
которые не имеют прямого отношения к значениям элементов последовательности, но имеют отношение к обеспечению 
последовательности некоторыми дополнительными свойствами. К таким полям и признакам можно отнести маркер времени,
признак уничтоженности, признак isnull. Индексы должны иметь дело только с опорными классами, интерфейс будет 
IBearing. Итак, возращаюсь немного назад и создаю новый интерфейс и классы BearingPure и BearingDeletable. Первый 
будет хранить только "чистые" значения элементов, а второй - еще и признак deleted.

Вот и заработали первые сборки. Пока на основе BearingPure, но потом проверю и использование другой опоры. Работает
не быстро, но уж такой компьютер. 
1 млн. load 3.7 сек., GetAllByKey 163 /1000

Через удаленный терминал проверил программу на рабочем компьютере, результаты положительные, но заметно лучше по 
скоростям:
1 млн. (стационарный) load 0.7 сек., GetAllByKey 15 /1000

По скорости ввода, лучше в 5 раз, по выборке - более, чем в 10...

А что теперь? Работы уйма, но что приоритетнее? 

### 20190506 07:06
Сейчас проверю то, что BearingDeletable работает и пойду в поход, к Сарлыку. 

Сделал, исправил ошибки, заработало. Замер следующий:
1 млн. load 3.7 сек., GetAllByKey 168 /1000

Это хорошо подходит к "чистой" опорной последовательности. Правда результаты измерений не стабильны,
так что это лучшие. Перешел в испытаниях на toload=false, результаты "прыгают", но в целом
соответствуют ожиданиям: по вычислениям 232, 132 (!), 152, 224, 157, 163, 150. И еще, после 
перезагрузки комьютер долго "устанавливается". В общем - ожидаемо.

Что теперь? В дальнейшем нам понадобится уничтожение записи. Причем это будет выглядеть как 
уничтожение всех триплетов, имеющих заданный субъект. После Уничтожения, будет добавление 
нескольких, относящихся к записи. Экономнее было бы сделать некоторый Update. При этом задаются
новые триплеты, если из новых, триплет уже есть, то его не менять и не уничтожать. Если нету,
то добавлять, если в сущестыующих, есть триплет, не предложенный в Update, то его следует 
уничтожить. Это функционально полный эквивалент пары уничтожить-добавить. Экономия будет в 
перевычислении индексов. 

Посмотрим на индексы в динамике работы с триплетами. Если добавлен единичный триплет, то
Сигнал об этом дойдет до двух индексов s и t или d. В индексе s имеется корректируемая
по предыдущим соображениям "картина" - офсеты всех триплетов, с данным субъектом или этот
вход пока отсутствует. Собственно именно эту "картину" надо изменить. В принципе, эту "картину"
можно менять общим оператором Update или по одному изменению. Логично рассмотреть одиночные
изменения. Пусть есть новый триплет. В s-индекс добавим вход, если его там еще нет и 
"приделаем" ко входу все необходимые офсеты. Если триплет объектный, то надо сделать 
изменения в индексе t. Если это триплет-значение, то изменения надо делать в индексе d.

### 20190507 04:46
Судя по всему, мне надо доделывать индексы. Однако, я сообразил, что есть еще некоторые 
сомнительные аспекты. Я имею ввиду понятие ключа. Вообще, что из себя должена представлять 
динамическая часть индекса? Какая задача решается индексом? По некоторому заданному значению
определяются один или несколько элементов последовательности, которые как-то соответствуют
значению. 

В этом нет точной постановки типа key-value. Но значение есть. Этому значению могут 
соответствовать или "точные" решения или "приближенные". Точное решение, это когда метрика
в прострастве значений - "совпадает/не совпадает". Можно говорить о множестве ключей. 
Возможно, я совершаю методическую ошибку, когда функцией ключа называю хеш-функцию (ключа).
Просто так удалось свести: функция ключа и компаратор, в целом решают ряд задач. В частности,
они решают задачу порядка сортировки элементов. 

Короче, надо позаниматься индексами. Опорной последовательностью я уже познанимался и не
вижу серьезных проблем, каторые требуют срочного вмешательства. Опорная последовательность 
не сортируется, не имеет "своих" динамических частей. Является всего лишь носителем множества
элементов. Что не сделано, так это добавление, уничтожение и замена элементов. Мы договорились,
что замены элементов средствами опорной последовательности не будет. Хотя в будущем, к этому
можно будет вернуться. 

Итак, надо реализовать методы:
```
    long AddItem(object obj);
	void DeleteItem(long off);
```
Причем выполнение этих методов должно содержать и коррекцию индексов:
```
    void OnAddItem(object item, long off);
	void OnDeleteItem(object item, long off);
```
Соответственно, что должно делаться? В случае добавления айтема (упаковываемого в элемент
объекта), просто упаковывается и добавляется. Ну и Flush(), чтобы не забывали. Уничтожение
айтема происходит проставлением признака deleted. Остальные действия должны выполняться 
хендлерами, отрабатывающими реакцию на операторы.

Попробую сделать оба метода. Хендлеры - потом.

Сделал. Пока только для BearingDeletable, для другого (других) варианта надо изучать 
возможности особо. Вроде, работает. Теперь надо подумать о хендлерах. Что надо сделать
с индексным построением, когда добавляется айтем? Совсем ничего делать не получится. 
Хотя бы потому, что новый айтем не будет "виден" через индексы. Его можно будет найти 
только с помощью сканирования или выдачи потока айтемов. Значит, надо фиксировать! Есть
какие-то индексные построения. Мы не собираемя сортировать, так что их трогать мы не будем.
Будем выстраивать динамическую структуру. Типа словаря, в котором есть поле ключа и есть
поле значения в виде офсета элемента, в который упакован айтем. А что же взять в виде 
ключа? Беру простейший индекс IndexViewImmutable. Там есть ключевая тема - компаратор.
Без компаратора сортировка была бы невозможна. Легче было бы если бы был задан не
компаратор, а какое-то поле, а значит - тип значения этого поля. Вот он "естественный"
вход в словарь. Подается слово, оно или является поисковым, или добавляется вместе со
значением в добавление айтема. Ночью я эту ситуацию анализировал и не придумал ничего 
лучше, чем объявлять в индексе ключевую функцию. Соответствие этой ключевой функции 
компаратору, путь будет на разработчике. 

А есть ли альтернативы? В качестве типовой альтернативы, мы используем искусственно 
созданные записи. Наверное, можно и так, но будет громозко и неэффективно. И что будет
означать значение { subj, -1, null }?

И все же, я поторопился с заключением. Я еще подумал и вышел к следующим рассуждениям.

Если есть индекс с компаратором, то ситуация не такая сложная. В оперативной зоне индекса
надо всего лишь сохранять новые элементы. А потом, используя компаратор, выбирать из этого
множества значения, удовлетворяющие условию равенства нулю между образцом и сравниваемым 
элементом. Небольшие объемы такой дополнительной индексной информации можно держать списком,
объемы побольше - сортировать тем же компаратором. 

Другое дело - ключевые индексы. Хотя в принципе, можно поступить также. Сохранить добавляемые
элементы и проверять по паре хеш-ключ - компаратор. Можно поступать по-другому: выстроить из
значений хеш-ключа хеш-таблицу (Dictionary) и прикрепить к ней все значения, совпадающие
по хешу. Проверять нужно также в двух местах: в динамической структуре и в Immutable индексе. 

Есть, похоже многочисленные, оптимизации о которых не хочется сейчас задумываться. Например,
можно в словарях хранить не офсеты, а сами объектные значения. Но тогда может "пострадать"
логика уничтожения. Буду считать, что с добавлением я справился. Теперь подумаю об 
уничтожении. 

Что есть? Есть айтем. Айтем, возможно, породил информацию в индексных построениях. Как мы 
выяснили, айтем может попасть в список соответствующего индекса, может в несколько списков.
И что? Там его проверяют какам-то компаратором. Причем делается это сначала "втемную":
есть множество офсетов, по ним считываются (если не уничтожены), объекты значений, их и
проверяют. Главное, что уничтоженность айтема сразу и непосредственно влияет на его 
использование в индексном компараторе. Вроде вообще ничего делать не нужно! Простое решение!
Дальше идут многочисленные оптимизации. Например, при проверке какого-то списка, выяснив,
что айтем не может быть задействован, его можно дополнительно убрать из списка.

А когда векторная индексация, тогда что? Пусть добавлен айтем. Векторный индекс извлечет
из айтема варианты слов, которые могут быть важными. 

Похоже, с векторным индексом все не так очевидно. Действительно, одним полем офсета здесь
"не отделаешься". Напр. если делается разбор текста, то в разобранном варианте есть первое,
второе, третье слово. Индекс должен состоять, как минимум, из пары { слово, офсет }. Это в
заметной степени отличается от более традиционного скалярного индекса, в котором мы часто 
можем обойтись без ключа, средствами одного компаратора. 

Попробую подвести промежуточные итоги. Добавление айтема достаточно просто влияет на простые
индексы. Что такое простой индекс? Это когда задача индексации сводится к использованию 
некоторого компаратора. Тогда при индексации, образец сравнивается с новыми элементами,
помещенными в список сравнения. Все аналогично для оператора уничтожения айтема. Там надо 
просто изъять айтем из любого списка, в котором он может находиться. "Изымание" производится
отметкой признака deleted. Вроде все! С векторными индексами я поработаю позже. 

Попробую эту логику вставить в код и, самое сложное, попробую придумать способ проверки.

### 20190508 05:48
Сегодня день рождения нашего младшего внука Демьянчика! Надо будет поздравить вечерком.

А вчера я "напахал" изрядно, надеюсь, что не "напортачил". На всякий случай, основные 
изменения сделал в копиях классов. Хотя и изменения небольшие, но принципиальные. Вроде
везде удалось избавиться от Immutable-классов. Теперь динамика вставлена непосредственно
в индексы. Соответственно, Теперь базовыми индексами являются IndexView и IndexKey32Comp.

Кажется, я не улавливаю какой-то тонкости. Попробую ее уловить. Итак, речь идет о добавлении
элемента в последовательность. Прямое включение в набор выполняется (слишком) просто. Также
как и исключение. Я анализирую изменения, которые надо делать в прикрепленных к 
последовательности индексах. Надо "отметить" появление или уничтожение элемента. Индексы,
в моем случае, это способ добраться до элементов, удовлетворяющих условиям. Что я все время
упускаю, элемент ВООБЩЕ может не быть применим к данному условию. Например, в IndexKey32Comp
применимость или неприменимость регулируется вычислением на элементе 
```
IEnumerable<int>> keysFun
```
- функции, которая вырабатывает 0 или 1 (пока не анализировал может и много) ключ. Если
0 - то элемент считается неприменимым к данному индексу. Соответственно, его можно не 
добавлять к индексному построению. А вот в IndexView такоей возможности "отсеять" элемент
из индексного рассмотрения кажется нет. А нуже бы. Напр. в случае хранилища триплетов,
сроковое сравнение применимо далеко не для каждого триплета. Посмотрю, как я "выкручивался"
в этом вопросе.

Итак, анализ показывает, что важную роль играет функция применимости для конкретного 
индекса. Эта функция, будучи вычисленной на значении айтема, определяет применимость айтема
как кандидата на выборку/поиск по данному индексу. Для ключевых индексов, я использовал 
свойство множественности результата ключевой функции. Если не порождается ни одного ключа,
то значение неприменимо к данному индексу. Если 1 результат, то стандартный скалярный 
ключевой индекс. Если порождается несколько ключей, то это уже векторный индекс, я его пока
серьезно не анализировал. В принципе, векторный индекс довольно прост: есть функция,
попрождающая по айтему набор (ключевых) значений. Пары ключ-офсет становятся поисковым
полем и на ключ-образец, выдаются все айтемы, которые породили подобный ключ. 

Динамическая часть индекса может быть такой же, как и при скалярном индексе. Только вместо
пары { объект, офсет }, в динамическую область поиска попадают сгенерированные
{ ключ(i), офсет }. Соотвественно, поиск в динамической части заключается в поиске по
заданному ключу-образцу пар, в который есть этот самый обазец. А потом, надо прочитать 
запись, проверить не уничтожен ли айтем и извлечь айтем из записи. 

Все просто и ясно. Это по поводу того, как отрабатывать добавление айтема. Добавляем, 
вычисляем ключи, образуем пары, вносим пары в оперативную зону. Похоже, что как и со
скалярным индексом, специальных действий производить не надо. Достаточно того, что 
по офсету читается запись и у нее проверяется признак уничтоженности. Возможно, 
понадобится оптимизация динамической структуры. Например, организация более эффективной
организации. Напр. что-нибудь вроде SortedList. Но в библиотеке Framework я подходящего
класса не нашел. Вот эта последняя оптимизация относится ко всем динамическим решениям.

Один из выводов, который можно сделать, это то, что для скалярных индексов нужна специальная
функция Func<object, bool> applicable. Для векторных индексов, нужна функция 
```
Func<object, IEnumerable<object>> keysFun
```
А функцию с аналогичным названием, надо переделать в 
```
Func<object, int> hashFun
```
При этом, вычисляться будет только одно значение. В некоторых случаях, hashFun сможет 
использоваться в виде ключевой функции, напр. если выделено целочисленное поле с (почти)
уникальным целым множеством значений.

Попробую внести изменения.

Внес. Заработал IndexKey32Comp. Результаты:
1 млн. load 3.9 сек., GetAllByKey 130 /1000

Не факт, что программа работает быстрее, по-прежнему большой разброс в измерениях.

Я не доделал программу и не тестировал программу. Начну с первого.

Там главное обработать и статическую часть и динамическую. И выдать объединенный результат.

### 20190509 10:14
День победы! Ура, ура, ура!

Сегодня я хочу постараться доделать основные решения уровня библиотеки "опорная 
последовательность - индексы". Начну (продолжу) с IndexKey32Comp. Там пока много мусора,
надо его "разгребать", но вначале динамическое решение. Здесь удобно применить словарь:
```
    Dictionary<int, List<long>> dynaKeyIndex;
```
В этом словаре списки офсетов айтемов, попавших в динамическую область, группируются по
ключу (хеш-ключу) от значения. Внесу изменения.

Изменения сделал, теперь испытываю. Еще вспомнил про компаратор, я его совсем не использовал
в действиях, а нужно обязательно. ... Вроде подправил. Все не как не могу добраться до 
испытания.

Нашел недоделку в методе GetAllByKey(key), сейчас исправлю. 

Потихоньку сделал индексы и их слабую динамику. Пока слабовато тестирую эти моменты, но 
более тотальное тестирование требует дополнительной изощренности, на которую я сейчас не 
способен. В реализации опорных поледовательностей и индексов к ним, остался "мусор",
который пока не убран, поскольку его надо еще выявить и понять что он действительно уже
не нужен. 

Сейчас уже глубокая ночь, надо идти спать. Завтра постарась продолжить. В принципе, путь
к триплетам открыт. 

### 20190510 16:03
Вчера я выразил оптимизм. Но не рано ли? Есть 2 смущающих меня момента: первый - испытания
IndexView с "близостным" компаратором дали плохой результат и, похоже, неправильный результат.
Неплавильный, потому что total выдал точно 1000, т.е. по одному результату на поиск. Тогда
как используется компаратор like, который на 6-символьных числах (100_000-999999) должен 
давать 1 результат на запрос, а на менее, чем 6-символьных - больше. Таких вариантов около
100 тыс., т.е. 10% всех случайных запросов. Буду разбираться. 

Разобрался. Исправил небольшую описку и проверил функционирование важных участков программы.
Работает несколько медленнее, чем я ожидал, но вроде "по теории". Есть еще одно соображение,
о котором я думаю с утра. Прореживание массива сродни технологии предвычисления. Это когда мы 
заранее вычисляем значения измеряемого объекта сначала в точке 1/2, потом в точках 1/4 и 3/4,
потом продолжаем делить отрезки и используем эти значения в том же методе бисекции для быстрого
доступа к значениям. Похоже, этот метод "идейнее", чем то, что я использую и может работать
быстрее. К этому я еще вернусь.

А пока можно подумать о планах на будущее. Только надо бы сохранить наработанное, также можно 
испытать на рабочем компьютере.

На рабочем компьютере испытание прошло успешно. Доступ по ключу - 15 мс. / 1000. Доступ IndexView
- 100 мс. / 1000. Все же хочется улучшить этот показатель. Но для этого, нужны правильные формулы.
Пусть есть единый ряд с индексами элементов 0, 1, ... n-1. В нем нет ни одного предвычесленного
элемента. Мы берем элемент с индексом n/2 и получаем диапазон "неизвестности" [0 - n/2-1], 
известное значение в точке n/2 и другой диапазон "неизвестности" [n/2+1, n-1]. Как-то очень трудно 
написать формулу. Но тогда может вычислить эти интервалы и точки. Первая точка деления n/2 будет
соответствовать индексу с младшим битом 1. Далее, будут заполняться точки 10 и 11 и так далее. 
Главное, вычислить индекс. Как-то также неубедительно. Можно попробовать двоичное разложение.
Предположим, у нас число точек равно 2 ** k. Тогда точка n/2 будет... Тоже как-то неубедительно.  





