
### 20190326 07:40
Решил, что писать программу в одном решении, а вести дневник в другом - неудобно, попробую приближать записи дневника к 
разрабатываемым. 

Итак, вчера я вышел на решение поиска по объекту. По крайней мере, показываются результаты, соответствующие ожиданиям. 
Теперь надо довести их до правильных. Кажется, для этого надо сформулировать компаратор и запустить его в работу. Снова 
проговорю логику работы индекса, работающего по полуключу. Есть множество элементов, на элементах задана ключевая функция
и согласованный с ней компаратор. Компаратор более "тонкий" инстумент, т.е. если значения ключей элементов различаются, то
в этом же направлении различаются и значения компаратора, но не наоборот.

Индексная структура формируется как множество пар (ключ, элемент) или (ключ, офсет(элемента)). Эта индексная структура 
отсортирована по ключу и по компаратору. Поиск по образцу заключается в том, что предъявляется образец, по нему вычисляются
все элементы, которые с образцом совпадают по компаратору (а значит, и по ключу). Это можно делать в два этапа. 
Сначала выделить диапазон, в котором тот же ключ. А потом в этом диапазоне проивести линейный или бинартный поиск.

Есть еще один вопрос для будущего, как учесть в индексе динамику изменений опорной последовательности? Не получается вариант 
с добавляемыми парами (ключ-значение). Предположение заключается в том, что в качестве динамической части индексного построения,
можно использовать что-нибудь вроде SortedSet<T>. Вроде все там в порядке и даже компаратор можно задать, но не очевидна 
сложность добавления элементов. Соответственно, мы новые элементы можем добавлять, а потом с ними сравнивать.

Я еще подумал. Вроде SortedSet не подходит. Нужен какой-то отсортированный по компаратору список элементов. Причем сравнение 
элементов может быть и нулевым. Чтобы к списку можно было бы легко добавлять элементы, не изменяя его отсортированности. Далее,
задается (конкретный) предикат, согласованный с компаратором. Требуется найти все элементы, удовлетворяющие предикату. Как эта 
задача решается? Предикат - это функция. Пусть задается "уровень" - функция, которая < 0 на "левых" элементах, = 0 на 
"центральных" элементах и > 0 на правых. Центральные и есть решение задачи. 

Запутался в логике построения ключевого индекса IndexKey32CompImm. Причем запутался в том месте, когда начинает использоваться 
компаратор. Логика построения такова: есть опорная последовательность и именно к ней строится индекс. Для этого, определяется 
функция ключа и строится набор пар {ключ, офсет}. Дальше массив сортируется, первично - по ключу, вторично - по компаратору. 
Компаратор сравнивает два объекта, соответствующих элементам опорной последовательности. Причем сначала сравнение идет по ключу,
а вторично - с помощью компаратора. 

### 20190327 06:53
Так вчера и не "распутался". Есть проблемы с сортировкой по полуключу. Есть проблемы с выборкой по ключу. Итак, вернусь
к конструкции. Есть опорная последовательность элементов. На ней задан ключ (полуключ). Формируется последовательность пар 
ключ-офсет и сортируется по ключу, вторичная сортировка производится по компаратору. Компаратар задан на объектном представлении
элементов опорной последовательности. Поэтому объекты компарации формируются из пары ключ-офсет через чтение из опорной таблицы 
объекта по офсету. 

Теперь о выборке. Есть простая выборка по ключу. Это хорошо работает когда нет компаратора. Предположим, мы можем сформировать
элемент-образец. Тогда мы можем ставить задачу выборки всех элементов из опорной последовательности, "эквивалентых" образцу
по компарации. Но это - "точная" выюборка. Можно попробовать так и сделать. Алгоритм следующий. Мы образец используем в делении
отрезка пополам и, с помощью компаратора, находим ноль, одно или более решение, удовлетворяющее условию сравнения. Этим у меня
занимается некоторая рекурсивная процедура. Процедура есть, но она не сформирована для работы с компаратором. Попробую это 
изменить. 

Сейчас поменял реализацию для нахождения всех записей по заданному ключу. Выборка ускорилась почти в 2 раза! Теперь по субъекту
получаем 1000 запросов за 8 мс. (77 мс. на 10 тыс. запросов). Внимательно посмотрев, я выяснил, что сделал не то. Я вопосльзовался 
массивом пар, расположенным в ОЗУ. Надо применить другое решение. Кстати, хорошо бы иметь понятный и эффективный интерфейс. Для
отдельного инедекса, это взятие всех решений по образцу. Но по образцу чего? Самый "универсальный" вариант - по "образцу" элемента.
Или по образцу объекта (или субъекта), который позволяет что-то. Наверное, на уровне индексного построения, когда у нас есть
ключевая функция и компаратор, правильнее будет подавать псевдоэлемент. Попробую.

Вернул характеристики на 14 мс. за 1000 выборок. Это по субъекту. Теперь буду работать по выборке по объекту. Буду работать 
поэтапно. Сначала только по ключу: сортировка и выборка. Потом подключаем компаратор, опять же: сортировка и выборка. Потом 
выборка по "похожему" значению. 

### 20190329 06:37
Вчера засуетился, много чего сделал, а вот проектом не занимался. Как-то надо исправлять ситуацию, тем более, что просыпаясь, 
я думаю об алгоритмах и логике. "Открытием" последних дней оказалось осознание того, что словарь "ключ-офсет" не является 
универсальным решением для выстраивания динамической части индекса. Видно, что надо использовать что-то вроде SortedTree, но 
такого класса в стандартной библиотеке нет. Возможно, в динамической части индекса лучше оказаться от сортировки и пользоваться 
простым List<T> или LinkedList<T>. Или делать двухуровневую динамику, когда есть напр. SortedList и есть List. Правда SortedList
обладает двумя недостатками. Во-первых - это key-value коллекция. Во-вторых - ключи не могут повторяться, но наверное, это 
следствие первого свойства. 

Вернусь к тому, что надо делать прямо сейчас. Сейчас я работаю над полуключевым индексом. Первое действие, надо существенно 
ускорить сортировку. Идея естественная: сначала пары сортирую по ключу, потом для каждого ключа, идет выделение множества
элементов опорной последовательности и производится сортировка по компаратору. После этого, все пары переписываются из массива
в последовательность. Действую.

18:27

Еще утром сделал двухуровневую сортировку. Построение Build() индекса происходит за 900 мс. (1 млн. триплетов). Теперь 
буду пробовать правильно сделать поиск. 

### 20190330 08:15
Наконец, заработали решения построения индекса на основе ключа и полуключа. В тесте, индекс по субъекту строится на основе 
ключа, индекс по объекту строится на основе полуключа. Для 1 млн. триплетов, оба индекса строятся 4.3 сек., 1000 выборок 
для ключа выполняется 14 мс., для полуключа - 107 мс. В принципе, это не так плохо.

Попробую пропустить тесты на больших размерах данных. 

1 млн. 4.3 сек., 14, 107
10 млн. 47 сек., 27, 151
100 млн. - Ушел в свопинг при загрузке данных (компьютер 8 Гб ОЗУ)

На работе (16 Гб ОЗУ)
1 млн. 5.5 сек., 19, 153
10 млн. 58 сек., 29, 206
100 млн. 755 сек., 19 сек., 279 (ОЗУ использовалась на пределе, странный результат по выборкам по субъекту), диск 3.7 Гб.
100 млн. без загрузки (Refresh) 11 сек., 19, 224

Есть еще режимы, которые надо бы проверить. Первое использование хеш-функции в качестве полуключа. И второе - использование 
функции уровня. Функция уровня задается на элементах опорной последовательности и принимает значения (отрицательное, 0, 
положительное). Выборка формулируется как выборка всех элементов, которые на этой функции равны нулю. Надо попробовать.

Делаю тестовую программу 15. Вернулся к последовательности персон:
```
PType tp_person = new PTypeRecord(
    new NamedType("id", new PType(PTypeEnumeration.integer)),
    new NamedType("name", new PType(PTypeEnumeration.sstring)),
    new NamedType("years", new PType(PTypeEnumeration.real)));
```
Организовал таблицу UniversalSequenceBase, сделал ввод. Миллион записей загружался 300 мс. Теперь добавляю индекс. 
Для начала - на идентификатор. Загрузка стала дольше - 635. Теперь вычислю тестовый запрос. Тестовый запрос правильный,
время выполнения 1000 запросов по идентификатору 12 мс. Испытание на большие размеры
1 млн. load 632, 12
10 млн. load 6.4 сек, 13
100 млн. load 64 сек, 14 
100 млн. без загрузки refresh 900 сек, 14 

Теперь сделаю другие индексы. Более простое решение - исплользование хеш-функции в качестве полуключа. Метод имеет тот 
недостаток, что нарушается монотонность. В частности, это означает, что не видно возможности делать выборки по близким 
именам. Итак, надо написать ключ, далее - посмотрим. 

1 млн. load 980, 19.  total=1003
10 млн. load 10 сек., 20.  total=1076-1100
100 млн. load 102 сек., 22.  total=1300

В общем, все по теории. Но здесь я получаю все решения, хеш-ключ которых, совпадает с хеш-ключом образца. В принципе, 
есть два решения задачи выборки по ключевой функции. Первое решение - фильтровать промежуточный набор и доводить его
до нужного. Второе решение - воспользоваться всем "могуществом" двойной сортировки, заложенной в IndexKey32CompImm.
При этом, мы потеряем что-то. Посмотрю как это будет выглядеть в на этом примере. 

Я проделал все манипуляции "в лоб" - соорудил индекс, там указал функцию (хеш)ключа и компаратор. По реализованным правилам,
если есть компаратор, то шкала не создается. Отсюда и более значительные времена обработки запросов. Теперь 10 млн. персон
обрабатывается: load 40 сек., 1000 выборок по имени 83 мс.

### 20190331 03:49
Что-то не спится... Попробую "наработать" желание поспать.

Вывод из предыдущих построений: надо сохранить обе возможности для получения решения - и фильтрацию после выборки по 
хеш-ключу и бинарный поиск по полному ключу. Теперь надо разобраться с поиском "близких" значений. Сортировку общего плана
я сделал в IndexViewImm. Но она трудозатратна. Это потому, что либо весь массив последовательности долже быть загружен в ОЗУ,
либо будет многократное обращение за элементами, лежащими на диске. 

Я применил IndexViewImm - он основан на ОЗУ и работает быстро. 19 мс. на 1000 выборок. Класс надо бы пределать, но сейчас это 
не так важно. Думаю поработать над этим классом и приведением его в норму. Для этого, для начала, нужно сделать работу с диском.

Кстати, пришла в голову новая идея. Делаю кодирование исходя из статистики. Написал код буквы, потом следующая буква 
определяется следующим кодом. Как-то не так сформулировал. Нам нужно кодировать цепочку символов. Можно использовать частотное 
кодирование, можно - более сложное. Частотное кодирование можно брать из статистики текущего варианта текстов. 

Итак, делаю "чистый" стенд в котром будет загрузка последовательности и вычисление только view-индекса. Итак, "чистая" загрузка
3280 - собственно загрузка. Вычисления - 13 мс. на 1 тыс. запросов. 
1 млн. load 3.3 сек., 1000run 13 мс.

Что-то странным образом изменилось и теперь вычисления выполняются 5 мс. на 1 тыс. запросов. Это на массивах в ОЗУ. Переношу 
вычисления на индексную последовательность. Возьму фрагмент в базовом ключевом индексе.

Вроде получилось! Единичная проверка прошла успешно. Время выполнения 1 тыс. запросов 130 мс. Неплохо!.. Но можно сделать лучше.
Есть такая идея: сделать "редкий" массив значений. Сначала находим интервал в массиве, потом в интервале ищем решение. Интервал,
правда, может объединить несколько отрезков. Как всегда, нас интересует количество обращений к диску при поиске. При бинарном 
поиске, для одного миллиона мы имеем приблизительно 20 обращений. Если сократим интервал до 16-ти, будет 4. Как-то так... Можно 
даже попробовать. 

Проделал некоторый эксперимент. Заменил бинарный поиск в массиве на прямой поиск типа:
```
    var res = elements
        .SkipWhile(ob => comp.Compare(ob, obj) < 0)
        .TakeWhile(ob => comp.Compare(ob, obj) == 0);
```
Поиск работал очень долго - 63 сек. на 1 тыс. запросов. Это более, чем в 10 тыс. раз медленнее, чем с использованием дихотомии.
Попробую добавить дихотомию. Добавил дихотомию. И даже Turple. Теперь на массиве, поиск диапазона выполняется 19-20 мс. на 
тысячу. Системный бинарный поиск работает быстрее, но здесь несколько иная постановка и я не могу им воспользоваться. 
Постановка - найти (минимальный) диапазон в массиве elements такой что первая точка <=0, а следующая за последней точка 
- точно больше нуля. Нет нуля, нет искомой точки... Все же результат неплох. Попробую применить его. 

### 20190401 05:11
День математика, дурака, геолога, Ура!!!

Исправил кое-какие ошибки и... получилось!  
1 млн. load 3.9 сек., 1000run 37 мс.

Это не 13 мс., но и не 130... 

Сейчас подбирал Nfactor. Остановился на 40. Скорость получается несколько хуже - 42-43, но объем использования ОЗУ существенно
меньше. Диапазон высоких скоростей 16-20.

Если делать без загрузки, получается время 150-170 мс. на тыс. Это потому, что Refresh не делает этот массив. 

07:55

Оказывается, я забыл при измерениях сменить режис с отладочного на нормальный. Сменил, результаты 3.4 сек., 38 / 1000

Последний решительный шаг в том, чтобы выполлнять сортировку по частям. Думаю, сделать это "тупо". Сначала делается равномерное
расположение последовательности офсетов. Потом, мы делаем процедуру делания копии части последовательности. Потом делаем
выборку массива объектов и массива офсетов и сортировку по компаратору. Потом начинаем делать сливание массивов с использованием
сравнения. 

19:23

Возвращаюсь к разработке. 

Сделал первую часть: создаю последовательность офсетов, определяю рекурсивный метод 
```
Bld(long start_ind, long number)
```
который сортирует отрезок офсетов по значению объектов. Потом применяю функцию и потом вычисляю разреженный массив. Все
это заработало в режиме, когда используется только оперативная память. Работает с теми же скоростями, что и раньше. 
```
1 млн. load 4.3 сек., 1000run 40 мс.
10 млн. load 47.8 сек., 1000run 61 мс.
20 млн. load 108 сек., 1000run 85 мс.
40 млн. load 500 сек., 1000run 474 мс. - свопинг
```

### 20190402 15:15
Сделал рекурсивную часть Bld. Но пока не работает. Начал отладку, похоже там две ошибки. Буду отлаживать отключив 
прореживание. 

### 20190403 09:51
Исправил ошибки, их оказалось несколько больше двух. Теперь запустил на большой тест, который засерит характеристики на
100 млн. элементов. Использование памяти пока ведет себя пристойно - потихоньку добралось до 7 Гб., теперь уменшилось до 5,
на задачу не досчитала. 
```
1 млн. load 4.3 сек., 1000run 38 мс. (131 без прореживания)
10 млн. load 47 сек., 1000run 60 мс. (171 без прореживания)
10 млн. noload 1.4 сек., 1000run 72 мс.
100 млн. load 1590 сек., 1000run 292 мс.
100 млн. noload 956 мс., 1000run 218 мс.
```

### 20190405 20:26
Теперь я мысленно нахожусь уже в реализации хранилища триплетов или хранилища записей. Как-то я не определился
в этом вопросе. Хранилище записей проработано неплохо, в частности понятны механизмы добавления, изменения и 
уничтожения. Запись может быть довольно произвольной структурой, Напр. такой:
```
REC = { id: string, fields: { prop: string, val: VALUE }, directs: { prop: string, direct: string } };
VALUE =  empty^ none,
	str^ string,
	langstring^ { lang: string, str: string};
```
Ну или как-то аналогично. К записям можно добавить отметку времени и признак deleted, после этого реализовать 
оговоренную логику слабой динамики. Возникает вопрос с обратными ссылками. 

Другой подход давно обдуман. В нем основной объект последовательности - триплет. Теперь к триплету "приделываем"
логику редактирования: временной маркер и признак уничтоженности. И делаем два (!) индекса spo и op (может ops).
Для качественного хеширования, берем 64-разрядное кодирование. Кодируем строки uri 63-разрядным хешем. А ObjectVariants
кодируем частями: вид - 1 бит, в случае uri, остальная часть - хеш-код. Если значение, то вариант значения. Базовые
варианты: строка, целое, дата, (языковый) текст. Может еще что-то. Spo Хеш-код триплета может выглядеть как: 32 разряда
Субъект, 8 разрядов предикат, 24 разряда объект. 

А если попроще и в рамках 32-х разрядов? Триплеты в проработанном варианте { uri, uri, OVars }. А индексы выстраивать 
неполные. Только по субъекту и только по объекту. По субъекту - просто. По объекту, я прикидывал ключ, состоящий из знака,
как признака Uri/OV. Потом идет целое или хеш целого. По другому варианту, это может быть хеш строки. 

### 20190407 05:52
Я подбираюсь к комплексному решению задач архивного комплекса. Архивного комплекса как распределенной информационной
системы. Можно назвать эту систему "островки" или "архипелаг". Второе - с ассоциацией на архивность. 

Пусть есть множество кассет. Причем как единичных, так и сгруппированных. Кассета, это множество (мультимедиа) документов
и фрагменты базы данных. База данных описывает документы этой группы касет или наборы сущностей, связаных или не связанных
хранящимися в кассетах документах. База данных хранится в формате модифицированного Turtle. Не знаю как насчет пространств
имен, но формат вполне удобен и компактен. Все его возможности мне не нужны, но простая компактизация с использованием 
разделителей ';' и ',' хорошо подходят для моих целей. А цель в том, чтобы изображать целостную запись и чтобы запись не
"расползалась" по тексту и по файлам. Нужен транслятор, но вроде больших проблем нет. 

Онтологию надо применять BONE. Есть некоторые системные расширения: владелец owner, отметка времени mT, isnull или deleted.

А нет ли проблемы в том, что я назначаю атомами триплеты, а транзакции выполняются с записями? Наверное нет, если ...

Итак, рассуждаю. Пусть имеются записи. Во внешнем представлении записи, это набор триплетов, имеющих общие субъекты и имеющие 
общую оболочку. Набор записей составляет один сегмент. Имеются e-сегменты, e это external, и имеются d-сегменты, d - data. 
Множество e-сегментов может быть преобразовано в d-сегмент, но не наоборот. Запись характеризуется идентификатором субъекта,
составляющих ее триплетов. Информационное поле (база данных) состоит из триплетов, составляющих объединяемые записи. Записи
с одинаковым идентификатором конкурируют между собой. "выигравшей" записью считается запись, имеющая более позднюю 
временную отметку. Отсутствие временной отметки трактуется как "очень давно" и любая запись с тем же идентификатором "выигрывает"
у такой записи. В e-сегментах может быть по нескольку экземпляров тождественных записей, в d-сегментах - только один. Отметка
времени - это триплет
```
<subj> b:mT "DateTime" .
```
Еще один служебный триплет - "обнуляет" триплет
```
<subj> b:isnull b:null .
```
Кажется, такая запись избыточна, можно заменить на что-то предикат или убрать (заменить на значение) объект. Но пока будем
действовать указанным образом. Самым сложным в общей семантике записей, является 
```
<subj> owl:sameAs <obj> .
```
И означает она, что все вхождения данного субъекта следует заменить на obj.  

20190408 06:37
Эквивалентность реализовывается с помощью кодирования. Это означает, что используемые uri кодируются, напр. целыми числами,
появляется таблица имен. В таблице имен проставляются одинаковые коды эквивалентным идентификатрам. Такая таблица имен требует
дополнительного построения и не слишком удобна в использовании. Последнее - поскольку ввод осуществляется за два прохода, первый
строит таблицу имен, второй - использует для собственно ввода. Итак, какая требуется дополнительная структура?

Сейчас вспоминал как это реализовано в нынешней версии. Реализовано не очень экономно. Выстраивается table_ri - словарь, имеющий
по входу на КАЖДЫЙ идентификатор, а основным значением словарного определения является список всех эквивалентынх идентификаторов 
данной цепочки. Поскольку ввод идет в два прохода, можно словарь уменьшить до размера только сливаемых идентификторов. Для этого
можно обрабатывать только указания эквивалентности. (Или ввести битовую шкалу?). 

Я проверил, действительно таблица table_ri выполнена неэкономно. А как нужно? Сканируются записи. Если в очередной записи
есть отождествление, то только в этом случае производится коррекция таблицы. Коррекция заключается в том, что проверяется
наличие обоих идентификаторов в таблице переименований. Если идентификатора нет, то вход для него заводится. Если есть, то
используется имеющийся вход. По обоим входам должна быть записана один и тот же список. Причем для других эквивалентных входов
список скорректируется автоматически. Это вообще возможно?  






