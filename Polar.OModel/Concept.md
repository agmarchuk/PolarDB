### Проект Polar.OModel

Начинаю новый проект. Хочу попробовать целостно реализовать концепцию объектной модели последовательности, изложенной в [].
Буду использовать некоторые классы из Polar.DB, если проект получится, то перенесу его именно туда. Итак, начну прямо по тексту
статьи.

Последовательность - это набор объектов. В данном рассмотрении, объекты будут только одного вида: простой объект или массив объектов. 
Возможно, будет иметь смысл ввести тип, напр. RObject, но пока не буду этого делать. Второй момент - объекты предполагаются типизированными 
через систему типов Поляра, а последовательность будет набором элементов одного типа. Типизацию возмем из Polar.DB в виде объектов класса 
PType. Присоединю тот проект к этому. 

В качестве тестового и конкретизирующего материала, использую тип Person. В поляровской системе типизации, определение будет:
```
Person = {id: Int, name: Str, age: Int};
```
Сериализацию берем такой, которая сформирована. Естественно, в реализации баз данных, больше подходит бинарная сериализация. 
Я посмотрел, похоже, класс UniversalSequenceBase нам полностью подходит. Расширение этого класса добавит недостающие методы редактирования.
Итак, что у нас получается? Делаем конструктор, пока повторяющий конструктор базы


Добавляем через конструктор две функции
```
private Func<object, bool> isEmpty;
private Func<object, DateTime> timestamp;
```
Первая указывает на то, что элемент "пустой", т.е. вроде как отсуствующий. Вторая выдает отметку времени данного элемента. 

Далее, надо бы наметить реализацию ввода и сканирования. Уже на сканировании я споткнулся. 
В результирующий поток хотелось бы чтобы попадали последние варианты элементов. Намечу канву: 1) Есть компаратор (ключевой), определяющий
эквивалентноть элементов. 2) Среди эквивалентных элементов оригиналом является элемент с максимальной временной отметкой. 
Базовым решением является перебор элементов последовательности с проверкой является ли данный элемент оригиналом. Для этого, из взятого элемента
извлекается идентификатор, а по этому идентификатору выявляется является ли элемент тем самым. Если "тот самый элемент" имеет отметку пустого, то
он также не выдается в результирующий поток. Проблема данного алгоритма в том, что на каждый элемент базовой последовательности требуется производить поиск.
Можно поступить наоборот, сканировать индексный массив, причем только на отличающиеся значения, а по полученным координатам элементов прочитывать их 
и формировать поток. В любом случае (я склоняюсь к первому), сканирование теперь должно выполняться в ключевом индексе.

После загрузки и сканирования можно испытать и потом пора заняться доступом.

### 20220303 06:51

Провожу испытание первой части реализации. Фактически, это испытание средств Polar.DB.

Проверил. Кое-что вспомнил, кое-что осознал или предположил. Например, последовательность ранее была фактически разбита на опорную последовательность и на 
индексы. В данной реализации, мы объединяем последовательность с индексами. Изменился и конструктор последовательности, в котором будет все что нужно. 

Теперь первично сделаю универсальный индекс.

Что-то начальное сваял, надо пробовать это оживить. Сначала поработаю с ключевым индексом, вставлю его определение в конструктор.

### 20220305 10:41
Надо двигаться дальше. Все пытаюсь собрать некоторый целостный начальный вариант. Какое-то время потратил на обдумывание методики включения универсального
индекса в обработку. Сомнения были относительно доступа к элементам по ключу. Общая форма предполагает использование образца, поэтому как правило,
надо конструировать искусственный образец и подавать массив. В общем, я с этой моделью свыкся и (пока) сделаю именно так.

Вернусь в универсальную последовательность. В ней будет один первичный индекс (primary key) и сколько-то других индексов. Начнем с первичного индекса.

С некоторыми трудностями, все же добился работу выдачи по ключу. Пока только очень локальной постановки. Надо проверить, что без загрузки тоже работает. 

Работает. Теперь попробую выявить потребительские свойства решения, попробую 1 млн. данных. 

### 20220306 11:49
Основной тест (загрузка, выборка) работает. Характеристики - не хуже, чем ожидалось. 

Что теперь? Надо расширять функциональность. В частности, надо добавить поиск по имени. И главное, надо сделать целостную систему 
редактирования. И еще, надо приделать получающееся решение в качестве движка к фактографическим системам. В общем, есть чем заниматься...
Кстати, есть еще "загадочный" третий файл, наверное, это шкала у индекса, но сейчас не время этим заниматься. 
Пожалуй, начну с первого пункта. Пора попробовать сделать движок.

### 20220308 13:20
В общем, дело оказалось не таким простым. Наверное, я мого чего забыл. Пришлось и вспоминать и преодолевать проблемы. Идея была и 
осталась в том, чтобы реализовать UniversalSequence и UniversalIndex по "лекалам" сформированным в разработке объектного подхода.
Создал проект, начал делать эти классы, в како-то момент, показалось что нужны изменения в уже сложившихся Polar.DB. Чего-то наваял, 
запутался... Пришлось начинать сначала, благо в репозитории есть та версия, с которой я начал. Со второй попытки что-то удалось 
сделать. Но поиск по Like не получился. Стал разбираться, понял (вспомнил), что этот доступ делается на основе общего компаратора
для строк с дополнительным использование компаратора like в момент организации поиска. В общем, сделал (вроде) начальный вариант 
универсальных классов. Пока это неизменяемые решения, построенные на базе UniversalSequenceBase, IndexKey32CompImmutable и
IndexViewImmutable. Можно двигаться дальше. 

Сделаю упрощенный вариант R-записи. И эти объекты упакую в последовательность. 

### 20220310 09:23
Ох как все непросто... Я закопался в вопросоах реализации универсальных последовательности и индекса. Из-за одной глупой ошибки
потерял кучу времени и написал много тестового кода. 

### 20220312 12:55
Добился работы простого теста последовательности перосон. Получил ожидаемые параметры. Теперь задумался об RDF. Набрел на мысль,
которая показалась катастрофической... Дело в том, что в имеющемся варианте основной процедуры поиска элемента по образцу,
видимо будет большое количество динамических действий. Каждое сравление с образцом будет выполняться долго. А ведь достаточно 
элементу сопоставить строковое значение критерия, потом легко будет производить поиск по базовому строковому Compare или по 
компаратору Like. 

В принципе, ситуация аналогична ситуации с выделением целочисленного хеш-ключа. Думаю, надо внести в новый индекс строковый ключ.
Есть смысл совместить этот вариант с векторым индексом. В конце концов поиск по имени порождает множественное отображение объект -> 
набор ключевых значений. Честно говоря, я не могу продумать все решение до конца, но думаю, все увяжется. И еще один момент. Ключ
можно объявить объектом, на котором есть метод ToCompare(). Но там могут возникнуть сложности с использованием строк...

Итак, как назвать новый индекс? Например: SVectorIndex. В нем будет последовательность строк и индексная последовательность к этой 
последовательности. Упорядочиваем лексикографически. При поиске допустимо применять like-компаратор. Попробую написать какой-нибудь 
код.

### 20220314 21:34
Хотя и коряво, но разработка идет. Уже достиг реализации поиска элементов и базовой визуализации элементов. Только без обратных дуг.
Именно на этом я застопорился. Как-то потребность реализовать обратные отношения не укладываются в стройную схему объекной модели.
Суть можно пояснить тем, что индексация предполагает сортировку элементов и в этом отсортированном множестве - поиск подходящих
ЭЛЕМЕНТОВ. В лучшем случае, обратные отношения дадут по идентификатору записи, получить все записи, которые ссылаются на эту.
А вот по какому отношению идет объектная ссылка, в таком построении не просматривается. Хотя и можно вычислить. Хотя и не точно...
Дело в том, что модель RDF позволяет между двумя узлами иметь несколько разноименных стрелок. 

### 20220316 07:12
Все думаю насчет обратных ссылок. Можно сделать классически - добавить векторный индекс "узлов на себя". Недостатоком решения видится то,
что теряется информация о предикате обратной ссылки. А можно сделать графовое решение в смысле обратных ссылок, "встроенных" в узел. Как в 
первом расширении RRecord. Все равно эта информация должна присутствовать в индексном построении. Есть минимальная избыточность построения:
обратный предикат. Вообще, с предикатами надо бы поступать более экономно, чем сейчас. В конце концов, идентификаторов предикатов обычно
совсем немного. Может 256 значений не хватит, но 2^^32 - более, чем достаточно. Это всего 4 байта. 

Попробую проработать вариант с графом. Основной (первичный) индекс для графа: индекс по идентификатору сущности. Дополнительный индекс:
поиск по имени. Какая-то реализация этого есть. Теперь обратные ссылки. Подозреваю, что достраивать граф надо уже после его первичного 
построения. Хотя может и не так. 

Как произвести достраивание? Рассмотрим поток записей. Будем формировать множество троек { subj, pred, resource }. Это касается только 
объектных свойств. Далее, производится сортировка по ресурсам и т.д. Альтернатива для не слишком больших данных - хеш-словарь с ключом в виде 
ресурса. Третий вариант: последовательность с первичным ключем уже есть и мы добавляем пары { pred, subj } к множеству свойств записи с
идентификатором resource. Надо посмотреть как сейчас выполняется формирование множества записей. 

### 20220317 08:46
Я в больших сомнениях. Как-то плохо выстраивается вектрный индекс в объектную модель. И прямое встраивание в граф обратных отношений также
плохо встраивается. 

Начну с модели. Важно, что для векторного индекса наиболее существенной является функция, определенная на объектах последовательности и
вырабатывающая массив (поток) объектов (v-объектов). При этом формируется виртуальное или реальное множество пар 
{ v-объект, ссылка на объект }. Далее, ситуация сводится к универсальной последовательности. Соответственно, задаются хеш-функция, задается 
компаратор. Выполняются действия по поиску и выборке. 

Можно пока вывести векторный индекс из рассмотрения. Я просто сформирую поток (массив) объектных триплетов, потом сгуппируем их по ресурсу 
и сделаем хеш-словарь. Его будем использовать при построении графа. Как-то так...

### 20220320 15:14
С утра по телеку сказали, что сегодня - день весеннего равноденствия. Странно,.. раньше было 21-22-го. Ну да ладно, весна вступает в 
свои права!

Еще вчера я добилася некоторых результатов. Главное - сделал "стандартую" загрузку FillDb. Вставил сборку мусора и это значительно уменьшило 
использование ОЗУ. Теперь уже и trs-адаптер выглядит неплохим. om-адапетер работает пока в режиме визуализации. 

Надо бы доделать om, хотя я уже начал сомневаться в его необходимости. Тут главное - концепция редактирования. Она должна быть их Объектной
Модели. То есть, надо ввести поле isnull и надо внести временную отметку. Причем верменная отметка на этапе базы данных необязательна. Почему?
Дело в том, что множество записей разбивается на статическое и динамическое, причем оба множества содержат элементы в единственном экземпляре. 
Если элемент есть в динамическом наборе, то он приоритетен. Если производится замена на новую запись, то она замещает старую в динамическом 
наборе. С другой стороны, временная отметка не мешает и соответствует временной отметке в XML-элементах. 

В общем, администрирование записями довольно простое. Непростой является коррекция сопряженных записей. Добавление, изменение и уничтожение 
записи может приводить к изменению взаимосвязей по прямым и обратным ссылкам. Прямая ссылка: не было/появилась, была/изменилась, была/пропала.
Возможно, такая же номенклатура изменений имеется и для обратных ссылок. 

### 20220322 12:00
Я уже довольно далеко отклонился от объектной модели, надо возвращаться. Но для начала, попробую испытать блазор-решение в среде открытого 
архива на сервере fan. 

### 20220326 07:36
Испытания затянулись. Кажется, я даже что-то покорректировал, но все же темп продвижения был почти нулевым. Все же я выяснил, что основная 
характеристика, которая меня интересовала, использование оперативной памяти, ведет себя вполне приемлемо. Иногда лучше, чем хранилище 
триплетов trs, иногда хуже. 

Снова попробую вернуться к адаптеру om - объектной модели. Нужно добавить слабую динамику. Запланированный вариант заключается в том, чтобы
добавить хеш-словарь записей. Но до этого, запись расширить на два поля: булевское isnull и tS - временную отметку типа DateTime. В данный
набор будут собираться записи, которые изменились с некоторого момента времени, скорее всего, после последней загрузки. Логика построения в
том, что оригинал записи может находиться в основном (статическом) наборе или в динамическом наборе. Динамический набор безусловно более
приоритетный для определения "оригинальности". Если происходит изменение записи, то новая запись зафиксируется в динамическом наборе либо
в качестве нового элемента набора, если ее там не было, либо через изменнеие имеющегося. Также должны последовать изменения, связанные с 
коррекцией связей новой записи со старыми. Корректируются только эффекты, получившиеся из-за изменений прямых ссылок. Если прямая ссылка 
претерпела изменение, то 1) в расширенной записи на которую была ссылка, из обратных ссылок убирается ссылка на фокусный элемент. При этом,
элемент перемещается в динамический набор; 2) новое значение ссылки также корректирует список обратных ссылках ссылаемой записи путем
добавления ссылки на опорный элемент. Можно эти действия "разорвать" тем, что не допускать произвольных изменений, а разрешать только либо 
создание прямой ссылки, либо исчезновение. 

Теперь про поиск по имени. В принципе, это векторный индекс. Можно новые записи обрабатывать на предмет новых имен, старые имена не 
корректировать. Тогда все просто: появилась новая запись, выделаем набор новых имен, новые имена помещаем в таблицу {имя, идентификатор}.
Можно санчала проверить, что там этой пары нет. Поскольку таблица имен не чистится от уже не актуальных пар, то при поиске можно предполагать 
наличие не актуальных и надо проверять. В общем, это все. Пока... Попробую что-то написать.

Кстати сообразил, что в запись RRecord ПОКА можно не включать временную отметку. Временная отметка ПОКА пишется в fog-файлы и используется при
загрузке. А вот признак пустоты isnull, надо внедрять уже сейчас. Поэтому структурно я введу оба поля, а использовать пока буду только признак 
пустоты. А на первом шаге, просто введу поля и проверю, что все работает. 

Еще одна коррекция: признак пустоты можно вставить в поле Tp, напр. использумый delete. В принципе, это ничему не противоречит поскольку
в модели важно не поле, а функция. Так что, на первом шаге мы вообще обойдемся имеющейся структурой записи. Тем проще. Попытаюсь соорудить 
какую-то реализацию PutItem.

### 20220327 13:27
Дело движется, хотя и медлено. Сейчас отлаживаю цепочку "уничтожить айтем" - "найти айтем по имени". Айтем уничтожается, но вторая часть
по-прежнему его выдает. В принципе понятно, где проблема. Я неправильно написал вот это нахождение 
IEnumerable<XElement> SearchByName(string searchstring).

Фокус в том, что найденных в малом списке не надо искать в большом. Точнее среди найденных в большом списке (последовательности), надо убрать
те объекты, которые найдены в малом. Похоже нагляднее будет работать в терминах множеств. Из "большого" множества найденных надо вычесть "малое",
А потом их объединить. Фокус в том, что эквивалентность элементов устанавливается через идентификатор. Вроде должно сработать...

Вроде пробился через тонкости. Надо было учесть и два набора в поиске по имени и два набора (основной и динамический) в записях. 

Теперь буду работать над новым объектом. Новый объект начинается с записи, не имеющей связей с другими. 

### 20220329 15:13
Наконец, движок OmAdapter заработал. Ура!!! Даже сразу не соображу чем заниматься. Пока потратил время на отзхыв для Артема Плюснина. 
Теперь собираюсь перед лекцией. Наверное, начну с простого: побреюсь, сменю рубашку, намечу план лекции.

### 20220505 23:03
Вот решил немного порассуждать. Оказывается, я пару UniversalSequence и UniversalIndex еще не доделал. Смотрю и вижу дефекты в реализации. 

Начал с последовательности. В универсальной последовательности по имеющейся концепции нет динамической части. Это чистая последовательность. Растущая последовательность с идентифицированными элементами, с временной отметкой и признаком пустого элемента. Последовательность развивается слева направо в том смысле, что более "правые" элементы с одинаковым идентификатором имеют более поздние временные отметки. 

Один из важных методов для последовательности - выдача потока всех элементов. Теоретически, этот метод можно реализовать без индексов, но практически, лучше и эффективнее сделать с использованием первичного индекса. 

Рассмотрим структуру пары последовательность - первичный индекс. Предположим, последовательность сформирована в момент загрузки. При загрузке можно обеспечить (!) единственность элементов с уникальными идентификаторами, т.е. остаются только оригиналы значений. Из этого следует то, что в построенном (Build) первичном индексе есть только по одному элементу на каждый имеющийся уникальный идентификатор из последовательности. Добавление элемента в опорную последовательность сопровождается помещением его в первичный индекс, но в динамическую часть. Помещением под имеющимся идентификатором. Если в динамической части такой идентификатор уже есть, то такой элемент заменяется. Другой вариант - помещение офсета нового элемента вместо самого элемента. Не знаю в чем разница. 

В итоге получается, что идентификатор может быть в динамической части или только в статической. Рассмотрим генерацию потока элементов из последовательности. Берем элемент из опорной последовательности и смотрим, есть ли его идентификатор в динамической части. Если нет, то очевидно, данный элемент подходит для выдачи в поток. Если есть, то надо сравнить временную отметку и при совпадении, элемент выдавать в поток, при не совпадении, элемент не выдавать. В этом процессе видна разница в организации динамической части. В случае хранения самого элемента, надо сравнивать временную отметку. Но если в динамической части хранить офсет, то сравнивать надо только офсеты. На этом этапе временная отметка уже не нужна. Да и напряжение на ОЗУ меньше... Пустое значение в этом процессе не помеха, только надо проверять и в случае пустоты, просто не пропускать. Таким образом, выдача потока всех элементов последовательности можно организовать максимально эффективно. 

Базовых методов для последовательности два. Один - доступ к элементу через первичный ключ. 

###20220506 09:47
Другие доступы выполняются через универсальный индекс. Попробую напомнить себе как устроен универсальный индекс. Причем с учетом динамики. Универсальный индекс строится на основе компаратора и целочисленной хеш-функции. Он является последовательностью офсетов элементов, отсортированных по комбинации хэш-компаратор. То есть, за каждым элементом индекса имеется одни и только один элемент опорной последовательности. Почему только один? Потому что иначе будут одинаковые точки, которые не различимы и непонятно что обозначают. Поэтому векторный индекс не реализуется с помощью универсального индекса.

Структурно, индекс может также содержать целочисленнное значение хеш-функции, заданной на элементах. Обязатльно то, что массив универсального индекса должен быть отсортирован по этому  целочисленному значению. То есть, если хеш-функция задана, то сортировка сначала ведется по ней, а уже потом по компаратору. Поиск по индексу выявляет все элементы, которые соответствуют образцу, т.е. и хеш совпадает и компаратор указывает на одинаковость. 

Рассмотрим некоторую динамику. Опорная последовательность может изменяться через: добавление элемента, уничтожение элемента, изменение элемента. При добавлении элемента все предыдущие элементы остаются, значит все предыдущие элементы индекса также сохраняются. Появляются новые элементы индекса, теоретически (при уничтожении и модификации) какие-то элементы перестают быть актуальными. Появление новых элементов отследить легко, надо отрабатывать хендлер OnAddElement или OnUpdateElement. 

### 20220508 12:07
В принципе, основная идея слабой динамики заключается в том, что добавляются новые элементы в индексный массив по мере добавления или изменения элементов последовательности. При этом, сатрые элементы не убираются. Далее, при выборках из индексного массива множества удовлетворяющих условиям индексных элементов, производится проверка (фильтрация) элементов на условие "оригинальности". Как это сделать? По индексному элементу, мы получаем офсет опорного элемента последовательности, по офсету мы получаем опорный элемент, в опорном элементе есть (?) информация об оригинальности элемента. 

Как-то не уверенно. А почему подбная схема проходила для первичного индекса? Там было четко: или искомый идентификатор находится в динамическом массиве или он находится в индексном массиве или его вообще нет. Во всех случаях (кроме последонего), Он там в единственном числе. И это - оригинал. 

Для векторного индекса надо иметь ввиду то, что элементы индекса могут быть уже устаревшие. Поэтому цепочка проверки такая: индексынй элемент, офсет опорного элемента, идентификатор опорного элемента, офсет опорного элемента, проверка на оригинальность по офсету опорного элемента. 

Итак, все множество (опорных) элементов имеет идентификаторы и офсеты {id, off}, идентификаторы являются уникальными для внешнего мира, но могут повторяться в множестве. Офсеты используются в качестве локального идентификатора, уникальные для каждого экземпляра. По офсету восстанавливается идентификатор. Также есть динамическое множество новых оригиналов. Это также множество     

### 20220512 09:28
Как трудно находить время для работы!..

Вернусь к универсальным индексам. Первичный индекс я уже разобрал. Скалярный универсальный индекс вроде тоже разобрал. Но все же повторю разбор. Напомню, что центральным сейчас является вопрос со слабой динамикой. 

Итак, UniversalIndex упорядочивает элементы опорной последовательности последовательно по хешу и по компаратору. Кроме того, некоторые элементы могут не входить в это построение. Соответственно, множество офсетов опорной последовательности, упорядоченных по критерию, является основным индексным массивом. Такой же массив, но уже динамический, поддерживается при изменении опорных элементов. Появление нового элемента совсем не меняет ситуации. Изменение элемента, для элементов, которые удовлетворяют индексному критерию, порождает потребность поместить этот элемент в динамический массив. При этом, он заместит элемент, уже имеющийся в статическом индексном массиве. То есть, ???

### 20220513 09:21
Ну хоть сегодня, хорошо бы сделать рывок в разработке. Единственное, что надо сделать - сходить сделать флюорографию. Пойду, провентилирую голову и тогда засяду за работу...

13:31
Сходил, но пока не очень получается "засесть за работу". Все же попытаюсь...

Сосредоточусь на слабой динамике для основных решений - первичного индекса, универсального (скалярного) индекса, векторного индекса. Гипотеза, которую надо бы подтвердить заключается в том, что при слабой динамике можно "не заморачиваться" коррекцией индесной структуры, а лишние решения отсекать простой проверкой. 

Для первичного индекса у нас, в результате добавлений слабой динамики появляются не только "правильные" элементы индекса, но и те, которые "неправильные". Но все "правильные" будут обязательно. Надо убрать неправильные. Чем отличаются "правильные" от "непрвильных"? Главное отличие в том, что это офсеты, ведущие на оригиналы. Проверка на "оригинал" для первичного индекса довольно проста: если пара "ключ-офсет" не назодится в динамической области индекса, то это безусловно оригинал. А если содержится, это тоже оригинал. Вопрос только в проверке динамического набора индекса. Надо иметь ввиду то, что первичный индекс не обязательно будет ключевым. 

Хорошо бы придумать какую-то удобную нотацию. 

Главное во всех процессах доступа при реализации слабой динамики, выбирать оригиналы. Для ключевого первичного индекса, мы можем устроить такое свойство, что в индексном массиве есть только один элемент с ключом, а если в динамическо1 части индекса для заданного ключа есть пара ключ-значение или ключ-офсет, то это также есть оригинал. 

Почитав код, я выяснил, что похоже пошел не по тому пути. Я постарался приспособить к первичному индексу скалярный универсальный индекс. Не уверен, что это правильно, но вроде доллжно работать. Дело в том, что в универсальном индексе нет четко выделенного ключа. Это может где-то сказаться. Альтернативно можно было  бы сделать ставку на векторный индекс. Но единственность решения может хорошо повлиять на эффективность алгоритма выборки.  

Все же посмотрю на схему реализации первичного индекса. Вне зависимости от того, ключеовй индекс или нет. Каждому элементу сопоставлдяется офсет и хеш. По ним производится сортировка индексного массива. Теперь, при наличии образца, можно получить элемент, соответствующий этому образцу. И по построению, элемент, находимый по образцу - единственный. Теперь пусть есть некоторый динамический набор пар {хеш, офсет}. Если есть образец, то определяем хеш, по нему находим все решения. Остается найти искомое решение. Искомое решений удовлетвояет двум условиям: 1) компарацией с образцом; 2) это оригинал. Первое проверяется считыванием элемента по офсету и проверкой. Второе условие можно не проверять если при включении пары с динамический список проверка была уже проведена. 

А что за проверка? Например, пары располагаются группами по хешу. При появлении новой пары, производится проверка совпадения с чем-то существующим по компаратору. Если совпадает, то замещает. Если нет, то добавляется. 

В чем будет отличие для "стандартного" универсального индекса? В принципе, ситуация очень похожая. Только выделить надо серию подходящих элементов. Вот и начинаем выделять сначала из динамической части, потом из статической части или наоборот. Главное, что каждое решение надо проверять. 

### 20220514 10:09
Одно я понял: ключевым является множество офсетов для случая скалярного индекса и множество пар {offset, value} для векторного индекса. Множества разбиты на статическую часть S и динамическую часть D.  

Рассмотрим случай скалярного индекса. Первое свойство - все офсеты разные. Просто по построению. Поскольку новый офсет в множество добавляется только при добавлении элемента в опорную последовательность, а это дает всегда другой офсет. Не уверен, что это существенное свойство, но офсет растет следва направо. Также по построению. Более существенным свойством является то, что во множестве S все идентификаторы также разные. Если предпринять меры, то и в D можно обеспечить то, что все идентификаторы будут разными. Действительно, при помещении офсета в D, можно найти офсет, у которого тот же идентификатор и просто заменить его новым. Если не найден, то просто добавить. Уникальность входа даст хорошие возможности для опримизации. 

Теперь рассмотрим векторный индекс. Здесь для одной опорной записи может быть несколько значений. Для множества S можно гарантировать то, что все идентификаторы являются оригиналами на момент формирования множества. Поиск решений в статическом массиве заключается в нахождении всех пар {o, v} таких, что v совпадает с образцом samplevalue. Для дальнейших действий нам будет удобно преобразовать пару {o, v} в тройку { o, v, id }. Все тройки с одинаковым id построены на основе одного элемента опорной последовательности. 

Теперь рассмотрим множество D. Там также на основе samplevalue можно выделить набор решений, превращенных в тройки. Для множества D надо добиться того же свойства, что все тройки с одинаковым идентификатором являются корректным решением. Это достигается тем, что на новой записи вычисляется векторная функция и порожденные ею тройки подменяют все, что было под этим иденификатором. 

Еще раз посмотрю на возможность формализации. Из множества S выбираем множество s3 троек {o, v, id}. Далее, мы группируем по идентификаторам. То же самой проделываем с множеством D, получаетм d3. А потом, находим пересечание множеств, вычитаем его из s3 и к результату добавляем d3: (s3 \ (s3 ∩ d3)) U d3   

### 20220515 07:57
Еще вчера догадался, что группирование по идентификатору для векторного индекса не получается глобальным поскольку поиск надо выполнять по значению. Это не отменяет локальных манипуляций с динамическим набором. 

Очень важнным является добавление нового элемента в опорную последовательность. Элемент имеет какой-то идентификатор и если такой в d3 уже есть, то надо устранять все тройки, которые имеют идентификатор id. А потом уже добавлять то, что получилось. Однако, это не "панацея". Если в новом наборе не будет этого идентификатора, то получится "разрешение" на взятие индексируемых значений из статического массива. Если процесс будет организован неправильно... 

Последние рассуждения поднимают значимость базовых критериев "оригинальности" опорной записи. То есть, для опознания того, что тройка {o, v, id} относится к оригиналу, надо по информации o-id это подтвердить или опровергнуть. Кажется, для этого достаточно один раз заглянуть в динамическую часть первичного индекса. По идентификатору мы выясняем есть ли там значение и, если есть, находим его офсет. Если нет, то дополнительной проверки делать не нужно, поскольку в статическом первичном индексе все пары {id, o} являются оригиналами при отсутствии id в динамической части. А если в динамической части значение есть, то остается лишь сравнить офсеты. Некоторым важным выводом может являться вывод о необходимости "сверхбыстрой" процедуры по выяснению является ли пара {off, id} оригиналом или нет. Минимально, это "заглядывание" в хеш-словарь динамической части первичного индекса. 

Теперь пора проводить эксперимент. Хочу заново запрограммировать и универсальную последовательность и универсальны индекс и универсальный ключевой индекс и универсальный векторный индекс. Поскльку некоторые названия запронированы, надо это делать в отдельном проекте. Пусть это проект называется Polar.Universal и, для начала, сделаю его консольным приложением. Главное отличие будет в том, что универсальные индексы будут законченными структурами. То есть содержать и статическую часть и динамическую. 

Уже пора писать комментарии. Проект я назвал Polar.Universal, в нем буду определять новую UniversalSequence, новый UIndex, также UKeyIndex и UVectorIndex. 

Работаю над созданием UKeyIndex. У него смысл аргументов конструктора несколько другой:
```
public UnKeyIndex(Func<Stream> streamGen, UniversalSequence sequence,
            Func<object, IComparable> keyFunc, Func<IComparable, int> hashOfKey);
```
Есть ключевая функция, определенная на объекте элемента последовательности, вырабатывает объект, удовлетворяющий интерфейсу IComparable.  Для объекта может быть определена функция hashOfKey. Ключевая функция определена на всех элеменатах последовательности.

### 20220518 05:12
Кое-что сделал, и это "кое-что" получилось. Сделал USequence и сделал ключевой индекс UKeyIndex. Для пробы, собрал тестовую последовательность из трех полей: целый ключ, строковое имя и целый возраст. Выборка по клаючу работает. Далее, мне не понравились скоростные характеристики последовательности и я решился на то, чтобы последовательность хеш-ключей активировать как массив. 1000 выборок была 130 мс., стала 16 мс. Вполне убедительно. Для преополагаемых объемов данных, плата за оптимизацию выглядит вполне умеренной. Тем более, что есть еще резервы... Я имею ввиду размещение хеш ключей в моследовательности с инвертированными индексами. Получив этот эффект, я заинтересовался большой задержкой, которая возникала при подсоединении к базе данных. Например, при отсутствии загрузки, подсоединение к базе данных со 100 млн. элементов происходило 25 сек. Пришлось найти причину. Эта причина оказалась в том, что при инициировании (через конструктор) уже существующей последовательности, очень важно найти конец байтового стрима. А для последовательности с переменной длиной элементов, я делал это сканируя последовательность. И в комментариях к коду было написано, что брать длину стрима нельзя поскольку стрим может не полностью использоваться при уменьшении количества элементов или изменении состава элементов. В итоге размышлений, я сообразил, что длину стрима можно задавать SetLength(long len), что я и сделал и перевел вычисление важного конечного офсета в просто запись текущей длины последовательности. После этого, удалось избавиться от этой "дурацкой" особенности и теперь последовательность работает "со свистом".

Что же дальше? Дальше надо:
- испытать последоватльность со строковым ключом;
- сделать универсальный индекс и испытать его на выборке по имени;
- испытать индексы в режиме слабой динамики;
- сделать векторный индекс и испытать его, в том числе в режиме слабой динамики. 

Попробую реализовать этот план. 

Пункт 1 сделал! Хотя и не без приключений. На тесте, в котором были строковые идентификаторы, часть запросов выдавала null, т.е признак отказа в наличии. Но только небольшая часть. Я быстро сообразил, что это из-за того, что хеш-функция иногда дает оиднаковые значения. Осталось найти. Оказалось это в новых оптимизациях. Устранил, заработало. Скорость - великолепная! Однако, надо проверить, что и старый вариант работает. Проверил, работает, только раз в 7 медленнее. 

Займусь универсальным индексом. Какие у него отличия от ключевого индекса? Основных - два. Во-первых, это множественность решений, во-вторых, наличие функции применимости. Может удастся несложными модификациями сделать его, тем более, что есть старое решение.

### 20220519 10:54
Ура! Я сделал часть универсального индекса, включая и Like-опцию. Испытал, работает. Надо бы испытать на скорость. 

Испытал. Исправил одну тонкую ошибку. Замерил время. В принципе, время выборки нормальное. Для 1 млн. элементов, выборка по 1000 запросов длится около 170 мс. А вот загрузка длится 136 сек. и это не выглядит нормальным. Надо будет подумать и сделать что-то. Но пока это не является существенным. 

Вроде выяснил природу того, что ранее ситуация с View-индексом и Like была существенно лучше в части времени загрузки. Дело в том, что последние эксперименты работали с частным случаем 

### 20220520 08:27
Вроде, все нормально. Я подумал по поводу длительности создания View-индекса, в типичном случае использования name-Like, это не помешает, поскольку надо делать векторный индекс. В другом, случае, который я надеюсь также станет распространенным, это когда формируется множество слов, это также использование векторного индекса еще с hash-функцией. 

По плану у меня уже 3-й пункт на подходе. Однако, я еще не доделал универсальный индекс и совсем не сделал слабую динамику. Пора озадачиться. Буду решать вопросы шаг за шагом. Сначала смотрю на USequence. По идее, в ней напрямую нет слабой динамики, однако косвенно, есть. Это, в первую очередь, касается добавления элемента. Там должны вызываться действия в присоединенных индексах. Добавлю это действие. Но более важно то, что изменяется первичный ключевой индекс. Как он изменяется? Все просто: добавляется пара { key, off } в динамическую часть. Пожалуй, сделаю это. 

### 20220522 15:24
Очень медленно, но я продвигаюсь по материалу. Кажется, я успешно завершил создавать универсальную последовательность и универсальный ключевой индекс. Даже проверил на слабую динамику. Далее, я сосредоточился на универсальном индексе. Вроде сделал и view-вариант и хеш-вариант. Даже сделал слабую динамику. Но не уверен, что сделал. Такое впечатление, что итот вид индекса сейчас не актуален... Более актуален векторный индекс. Причем в вариантах и совпадения и Like. Действительно, мне нужно сделать поиск записей по части имени и мне нужно сделать поиск по ключевым словам. 

Попробую сделать это решение. Попробую обойтись одним векторным индексом, value-функция которого порождает поток сравнимых значений. Это будет похоже на универсальный индекс, но есть особенности. Индекс я назову UVectorIndex. Не будет ключа и компаратора, но будет value-функция. И вместо функции применимости, будет та же value-функция, дающая векторный результат. Попробую сделать индекс, переделывая ключевой индекс. 

Сейчас сделал начало и остановился... Получается, что есть 4 согласованные последовательности, в которых распределена информацию об основном массиве индекса. И все это хозяйство надо отсортировать! Как-то не очень...

А если совершить смелый шаг? Оставить только пару element_offsets и hkeys? Как в ключевом индексе? К чему это приведет? Все равно, я буду прочитывать по офсету элемент, по элементу вычисляются величины. Но вычислются НЕОДНОЗНАЧАНО! Видимо, в этом некоторое ключевое затруднение. Если взять другую пару element_offset-value, то вроде лучше, но тоже не сильно получается. А если взять пару element_offset-value_offset, тогда как? Вся "соль" предыдущего решения была в том, что поиск сначала ведется в целочисленном массиве hkeys. 

В общем, не получается... Допустим, я вернусь к паре value-element_offset. И надо иметь оба массива в виде последовательностей. Потому что нет однозначного вычисления значения по офсету и, тем более, наоборот. Попробую так и поступить. 

### 20220523 15:41
Новые (универсальные) программы "задышали" и основные действия, требуемые при реализации RDF, теперь можно сделать. Попробую сделать новые адаптер. 

### 20220524 11:53
Адаптер я сделал, что-то заработало. Я обрадовался и решил, что все работает. Но нет... Испытания показали, что на больших данных , напр. soran1957, новый адаптер выдает какую-то ошибку и не запускает придложение. Понять что и как не получилось, придется возвращаться к отладке. Я действительно поспешил. Я "намудрил" с векторым индексом, универсальный скаларняй иддекс я пока бросил, поскольку пока нет его использования в базах данных. Ну и не испытывал адаптер на полубольших данных. 

И вообще, мне не нравится длительность загруки данных. Если сейчас открытый архив и фоторазив загружают данные около минуты, то что будет когда данных станет напр. в 100 раз больше? И не загружать нельзя - слабай динамика реализована в ОЗУ и требует полной презагрузки, чтобы эти данные былы активированы. Или перезагрузки хотя бы индексов. В общем, думать надо...

Наибольшая неудовлетворенность в том, как я решил вопросы с векторным индексом. Сначала я сделал универсальный векторный индекс, где значение имеет тип IComparable. Вроде все увязалось. НО потом "помучился" в районе сортировки и бинарного поиска. Оказалось, что опять наступаю на те же грабли, на которые наступал когда-то. Дело в том, что для русского языка надо учитывать некоторые сортировочные тонкости. Дефолтная сортировка строк, содержащих русские буквы выполняет это как-то так, что потом не работает бинарный поиск. Наверное нарушается неравенство треугольника. Устранить это на уровне сравнимых объектов я не знаю как, приходится переходить к строкам. Вот и получилось, что часть реализации сделана в сравнимых объектах, часть в строках. Подозреваю, что из этого места могут "вылезть" и другие проблемы. С другой стороны, не хотелось бы отказываться от сравнимых величин. Ведь это могут быть числа или что-то еще. Правда применимость чисел в векторных построениях возможно не такая частая. Похоже, надо выделить вектрные строки в отдельный класс. И оставить общий IComparable. 

Наверное, так и надо сделать. И сосредоточиться на оптимизациях в строковых значениях.  

### 20220525 08:55
Сделал раздел, кое-какие моменты нашел и исправил. Сейчас проверю все "веточки" слабой динамики и буду испытывать. Начиная от тестов и далее на реальных данных. 

Проверил основные решения. Только на универсальном индексе UIndex "споткнулся" и решил пока его отложить. Теперь буду проводить испытания. Для этого мне нужна последовательность из строкового ключа, строкового имени и, напр. строкового типа. А лучше, чтобы строковых имен было несколько. Пусть будет как в RDF-записях. Условие Tp="deleted" есть условие пустого значения. Для пустого значения существенными явлются только Id и Tp.  

Начну делать новый тест. Но сначала пропукаю старые тесты. Первый тест (Main1), сломался на GetAllByLike, причем на моем выбрасывании исключения по NotImplementedException. Второй тест сломался в таком же месте. Начну делать третий тест. 

Восстановил основную тестирующую программу. Загрузка 10 млн. записей выполняется 12 сек. !000 выборок GetByKey выполняется 15 мс. Перейду к проверкам слабой динамики и других индексных построений. На уровне последовательности, мы можем выполнять уничтожение, добавление и модификацию элементов. Там это видно через выборку, сканирование и поток элементов. Пробуем: элемент "2" уничтожаем, элемент "4" изменяем и добавляем элемент "aaa".   

Исправил какое-то количество ошибок и неточностей. Надоело... Попробую вернуться к адаптеру и применению в фактографических проектах. 

### 20220526 10:11
Заработала основа адаптера. Это основные доступы. Не работает форматная выборка и не работает запись элемента. Попробовал разобраться и, чувстую - закопаюсь... Дело в том, что я применил новый подход к реализации графа. Это когда расширенная запись содержит не только и не столько исходящие ссылки, а начала записей по исходящим ссыкам и даже - входящим ссылкам. В принципе, решение было доведено до рабочего состояния в объектной модели OM, но поддержание этих ссылок стало сложной логической задачей, которая меня теперь путает... Мне захотелось вернуться к более простому решению. А именно, пусть база данных будет набором простых записей и набором стрелок 

### 20220527 11:33
Поулчается, что прошли сутки с момента, когда я занялся доработками адаптера uni. И я эти сутки потратил на то, чтобы искать ошибку, которую сам же внес по невнимательности!.. Исправил, теперь редактирующие действия работают. Сейчас подчищу мусор, который породил для того, чтобы найти и двинусь дальше. 

Провел испытание на визуализацию через MagBlazor данных фотоархива. Все в порядке. Движок заняв 190 Мб. ОЗУ, что выглядит интересным. Теперь надо сделать форматный вывод. Думаю, что будет несложно переработать вывод, который делался для OM. 

Действительно, переделка оказалась минимальная. Однако, "вылезла" ошибка в организации сортировки. В данных была пустая строки и это с заданным коммаратором дало ошибку. Сделал коррекцию в компараторе, все работает. Перейду к испытанию а реальных данных. 

Soran1957 заработал. Использует 278 Мб ОЗУ. Может и меньше, но трудно оценить точнее. Теперь попробую открытый архив. Открытый архив также заработал. Но потребляет 833 Мб. Многовато... Думаю, надо иметь загрузку в режиме подключения, это даст более точную оценку потребляемой памяти. Придется подкорректировать код базы данных. 

Все работает. И даже потребляет не так много памяти - около 100 Мб. на каждое приложение. Теперь надо делать поиск по ключевым словам. Пока это будет со словарем. Словарь нужен для того, чтобы иметь перекодировку слово - нормализованное слово. Потом будем делать векторный индекс н.слово-офсет, где офсет соответствует записи, сгенерировавшей "слово". Предложения для генерации слов буду брать из полей name и description. 

### 20220528 08:25
Продумываю вектор ключевых слов. Надо пробовать. План такой: В адаптере uni завожу словарь Зализняка в zip-виде. При инициализации, рапаковываю словарь и превращаю его в хеш-словарь (Dictionary) слово-норм.слово. Убираю ненужное. Начинаю работать со словарем. 

Словарь делается тривиально. Основная сложность, как и где его разместить и как и где его активировать. Решил не связывать словарь напрямую с адаптерами, а активировать его при инициализации объектов класса OADB. Предполагается, что zip-файл словаря Зализняка имеется в корневом разделе wwwroot и это инициирует действие по распаковке файла и созданию словаря. В итоге, статический объект 
```
public static Dictionary<string, string> toNormalForm = null;
```
либо null, если нет Зализняка, либо хеш-словарь. 

Теперь надо этим словарем воспользоваться. Это делается уже в адаптере. Сейчас я работаю над uni-адаптером. В нем надо завести индекс, мы будем использовать SVectorIndex. Этот индекс надо "настроить" на выполнение Build и на выполнение OnAddElement. 

Рассмотрим схему поиска по заданным словам. По каждому слову мы находим записи, в которых это слово есть. Получается множество пар:
```
    {w, r}
```
Где w-слово, а r-запись. Потом это множество группируем по r, получаем для каждого r множество связанных слов. Потом

### 20220531 11:05
Ура, ура, ура! Я закончил делать вариант поиска по словам и опробовал его на данных фотоархива врежиме MagBlazor. Пока идеи исчерпались и надо будет нарабатывать новые. Пусть Сергей доводит то, что есть, а мне пора поработать над архивами. Идея такова: маме через 6 дней будет 95 лет, хочу к этой дате собрать семейные архивы, в первую очередь - мамины архивы. Еще хочу сделать генеаологическое дерево. Завтра надо будет зайти к Павловской и понять что они там сделали и как это можно использовать. А пока у меня еще "сегодня". Главное, что семейный архив нужен семье и не нужен научным архивам. 

Сначала надо разработать концепцию. Понятно, что основой будет фактографическая система, что для первичного формирования кассет будет использоваться CManager, что для редактирования будет использоваться какое-то Blazor-решение. Вопрос в том, как будет устроен основной пользовательсткий интерфейс. Пока не появилось новых идей, буду действовать "по-старинке", т.е. через портреты сущностей. Но для генеаологического дерева надо будет придумать что-то более понятно. Можно сделать переключение из режима портрета в режим дерева и наоборот. Есть еще одна задача: разработать технологию использования уже существующих кассет в других сборках. Базовая идея такого решения заключается в том, что автоматически собираются все дополнительные сущности и превращаются в локальный фог-файл. Появляется новая кассета, которую можно использовать вместо старой в разных архивах. Как-то так... 

Пока жду студентов, порассуждаю о делании копии кассеты. Как-то это надо назвать. "Специальная копия" как-то безлико, а как будет более ярко? 

### 20220601 05:28
Что-то не спится, попробую вернуться к рассуждениям о делании копии кассеты. 

Кассета, это хранилище документов. Среди документов могут быть фог-файлы. Причем если в копию поместить разные варианты документов и фог-файлы этой кассеты, то уже будет некоторая кассета. Правда в ней могуть быть переименования и уничтожения. Это касается документов. Директорная структура кассеты делается средствами распределенной базы данных. Также средствами распределенной базы данных делается привязка документов к другим сущностям. Можно взять цепояку "документ"-"связь"-"системный объект" и получится уже осмысленная база данных. Причем новую кассету можно поместить в действующие проекты вместо старой. При восстановлении объектов и связей базы данных, надо максимально использовать имеющиеся фог-файлы. 

Двигаюсь по анализу/синтезу кассет. Выяснил, что в текущей конфигурации фотоархива 5660 документов не имеют uri. Вопрос: а что они имеют? Посмотрел. Похоже, в основном, это документы с контентом и фотки с устаревшим указанием места публикации. Надо будет вернуться к таким фоткам. А сколько видео и аудио? Похоже, таких нет... Посмотрел внимательнее, видео есть, но они в кассетах, которые на загружаются. Пока это не существенно.

Добрался до документов кассеты gi_pharchive. Всего их оказалось 460, а сколько файлов? А файлов 445. Предположительно, это из-за каких-нибудь переименований, но надо бы выяснить. Пока ищи проблему, выявил еще одну ошибку/неточность. Адаптер xml по запросу GetAll выдает элементы в базовом XML-представлении. А надо в виде записей.  

### 20220602 09:19
И вот когда казалось, что все в MagBlazor уже сделано, выявилась существенная недоделка в одном из ключевых мест - работе с множественными значениями полей. В первую очередь, это языковые варианты. В данных есть разные языковые варианты имен персон, но выдается только один. Причем поиск провдится и по значению другого. С этим что-то надо делать. Попробую разобраться. 

Распечатывание сущности Патон... с идентификатром svet_100616111408_21334 показало, что есть два вопроса: ВО-первых, есть два поля на разных языках, это правильно. Во-вторых, запрос GetItemByIdBasic(patonId, false) выдает и обратные ссылки в некотором стандартном для XML-движка варианте. Второе обсточтельство может и не мешает, но где-нибудь в будущем грозит выйди в виде проблемы. Да и эффективность не очевидна. А вот что именно распечатывается в виде значения поля и что редактируется, это надо бы понять. И понять как все должно быть устроено.















